{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Hillfort detection with LiDAR data\n",
    "## Data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Table of contents\n",
    "\n",
    "[Code](#code)\n",
    "\n",
    "1. [**Defined functions**](#defined-functions)\n",
    "2. [**Data gathering**](#data-gathering)\n",
    "3. [**Data preprocessing**](#data-preprocessing)\n",
    "4. [**Data augmentation**](#data-augmentation)\n",
    "5. [**Data saving**](#data-saving)\n",
    "\n",
    "[End](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# import os\n",
    "# import re\n",
    "# import csv\n",
    "# import typing\n",
    "# import itertools\n",
    "# import json\n",
    "# import logging\n",
    "# import warnings\n",
    "# import evaluate\n",
    "# import types\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "# import torch\n",
    "# import math\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "import laspy # Reading LAS file format\n",
    "from tqdm import tqdm # Loading bars\n",
    "import geopandas as gpd\n",
    "import lib.download_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data():\n",
    "    lib.download_maps.process_csv('../data/linnamagede_ruudunumbrid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "137it [00:14,  9.53it/s]\n",
      "2024-11-18 19:29:38,794 - INFO - Total files: 153\n"
     ]
    }
   ],
   "source": [
    "gather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load area points from the text file and create a polygon\n",
    "def load_area_polygon(file_path):\n",
    "    coordinates = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if len(line.split()) == 3:\n",
    "                _, x, y = line.strip().split()\n",
    "                coordinates.append((float(y), float(x)))  # Swap X and Y for the polygon\n",
    "    return shapely.Polygon(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify LAS points' classification inside the polygon\n",
    "def classify_points_in_area(las_file_path, polygon, new_classification, output_path):\n",
    "    # Load the LAS file\n",
    "    las = laspy.read(las_file_path)\n",
    "    \n",
    "    # Extract LAS point X, Y (swapped) coordinates as tuples\n",
    "    points = np.column_stack((las.y, las.x))  # Swap X and Y\n",
    "    \n",
    "    # Create a mask for points inside the polygon\n",
    "    mask = np.array([polygon.contains(shapely.Point(pt)) for pt in points])\n",
    "\n",
    "    # Apply the new classification to points within the polygon\n",
    "    las.classification[mask] = new_classification\n",
    "    \n",
    "    # Write modified points to a new LAS file\n",
    "    las.write(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasterize a shapely polygon for overlay\n",
    "def rasterize_polygon(polygon, x_min, x_max, y_min, y_max, resolution):\n",
    "    grid = np.zeros((resolution, resolution), dtype=np.uint8)\n",
    "    x_range = np.linspace(x_min, x_max, resolution)\n",
    "    y_range = np.linspace(y_min, y_max, resolution)\n",
    "    \n",
    "    for i, y in enumerate(y_range):\n",
    "        for j, x in enumerate(x_range):\n",
    "            if polygon.contains(shapely.Point(x, y)):\n",
    "                grid[i, j] = 1  # Mask for polygon\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to blend mask into an image with transparency\n",
    "def apply_transparency(image, mask, mask_color, alpha):\n",
    "    # Create a copy of the original image to avoid overwriting\n",
    "    blended_image = image.copy()\n",
    "    \n",
    "    # Get indices where the mask is active\n",
    "    mask_indices = mask == 1  # Binary mask where 1 indicates the mask area\n",
    "    \n",
    "    # Blend mask color with the original image in the masked region\n",
    "    for channel in range(3):  # Loop over RGB channels\n",
    "        blended_image[..., channel][mask_indices] = (\n",
    "            (1 - alpha) * blended_image[..., channel][mask_indices] + alpha * mask_color[channel]\n",
    "        )\n",
    "    \n",
    "    return blended_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    mask_hillforts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kirjeldada, kuidas andmed koguti, mis takistused ja neile lahendused olid, kellega kokku puutusime andmete kogumisel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Andmete allalaadimine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Kirjeldada lühidalt andmetöötluse protsesse: tunnuste valimine, filtreerimine, hulkadesse (treening-, val-?, test-) jagamine, augmentation andmete juurde genereerimiseks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpulocal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
