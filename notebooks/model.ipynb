{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hillfort detection with LiDAR data\n",
    "## Data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "[Code](#code)\n",
    "\n",
    "1. [**Initializing and training the model**](#initializing-and-training-the-model)\n",
    "2. [**Evaluating the model**](#evaluating-the-model)\n",
    "3. [**Hyperparameter tuning**](#hyperparameter-tuning)\n",
    "4. [**Results**](#results)\n",
    "\n",
    "[End](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Imports\n",
    "import os\n",
    "# import re\n",
    "# import csv\n",
    "# import typing\n",
    "# import itertools\n",
    "# import json\n",
    "import logging\n",
    "import zipfile\n",
    "# import warnings\n",
    "# import evaluate\n",
    "# import types\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import torch\n",
    "# import math\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "import laspy # Reading LAS file format\n",
    "from tqdm import tqdm # Loading bars\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "   def __init__(self, k=3):\n",
    "      super().__init__()\n",
    "      self.k=k\n",
    "      self.conv1 = nn.Conv1d(k,64,1)\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      self.fc1 = nn.Linear(1024,512)\n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      self.bn4 = nn.BatchNorm1d(512)\n",
    "      self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "   def forward(self, input):\n",
    "      # input.shape == (bs,n,3)\n",
    "      bs = input.size(0)\n",
    "      xb = F.relu(self.bn1(self.conv1(input)))\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      flat = nn.Flatten(1)(pool)\n",
    "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "      if xb.is_cuda:\n",
    "        init=init.cuda()\n",
    "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "      return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "       \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "       \n",
    "   def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, xyz, labels, num_points=1024):\n",
    "        self.xyz = xyz\n",
    "        self.labels = labels\n",
    "        self.num_points = num_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xyz)  # Number of point clouds in the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        points = self.xyz[idx]  # Points for the idx-th sample\n",
    "        labels = self.labels[idx]  # Labels for the same sample\n",
    "        \n",
    "        # Ensure points is a 2D tensor with shape (N, 3)\n",
    "        if points.ndimension() == 1:\n",
    "            points = points.view(-1, 3)\n",
    "\n",
    "        # Padding to ensure every point cloud has num_points\n",
    "        if points.shape[0] < self.num_points:\n",
    "            padding = torch.zeros(self.num_points - points.shape[0], 3)  # Padding with zeros\n",
    "            points = torch.cat([points, padding], dim=0)  # Concatenate the points with the padding\n",
    "        else:\n",
    "            points = points[:self.num_points]  # Truncate if there are more than num_points\n",
    "\n",
    "        return {'pointcloud': points, 'category': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, criterion, m3x3_weight=0.0001, m64x64_weight=0.0001):\n",
    "    if not criterion:\n",
    "        criterion = torch.nn.NLLLoss()\n",
    "    bs = outputs.size(0)\n",
    "\n",
    "    # Identity matrices for regularization (to penalize transformation deviations)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs, 1, 1).to(outputs.device)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs, 1, 1).to(outputs.device)\n",
    "\n",
    "    # Regularization terms\n",
    "    diff3x3 = id3x3 - torch.bmm(m3x3, m3x3.transpose(1, 2))\n",
    "    diff64x64 = id64x64 - torch.bmm(m64x64, m64x64.transpose(1, 2))\n",
    "\n",
    "    # Compute the base loss (negative log likelihood)\n",
    "    base_loss = criterion(outputs, labels)\n",
    "\n",
    "    # Add regularization (transformation matrices)\n",
    "    reg_loss = m3x3_weight * (torch.norm(diff3x3) + torch.norm(diff64x64)) / float(bs)\n",
    "\n",
    "    return base_loss + reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pointnet, criterion, train_loader, device, val_loader=None, epochs=15, save=True):\n",
    "    optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64, criterion)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100. * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "        # save the model\n",
    "        if save:\n",
    "            torch.save(pointnet.state_dict(), \"save_\"+str(epoch)+\".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_las = laspy.read('../data/classified_lazFiles/397689_2023_tava.laz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV\n",
    "normalized_polygons = pd.read_csv('../data/normalized_polygons.csv')\n",
    "\n",
    "# Convert the list of WKT strings back to shapely Polygons\n",
    "normalized_polygons['polygons'] = normalized_polygons['polygons_wkt'].apply(lambda wkt_list: [shapely.wkt.loads(wkt_str) for wkt_str in eval(wkt_list)])\n",
    "normalized_polygons = normalized_polygons.drop('polygons_wkt', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laz_file</th>\n",
       "      <th>polygons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>397689_2023_tava.laz</td>\n",
       "      <td>[POLYGON ((0.2154821638250724 0.53317514155060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>402642_2023_tava.laz</td>\n",
       "      <td>[POLYGON ((0.559215598856099 0.702996839769184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402674_2023_tava.laz</td>\n",
       "      <td>[POLYGON ((0.7066870752023533 0.31486295908689...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>407676_2023_tava.laz</td>\n",
       "      <td>[POLYGON ((0.6727867362787947 0.95630937255918...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>407700_2023_tava.laz</td>\n",
       "      <td>[POLYGON ((0.119291202398017 0.732177131809294...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>596650_2022_tava.laz</td>\n",
       "      <td>[POLYGON ((0.9488594959257171 0.22939210943877...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>596651_2022_tava.laz</td>\n",
       "      <td>[POLYGON ((-0.0511505041504279 0.2293921094387...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>598586_2022_tava.laz</td>\n",
       "      <td>[POLYGON ((0.2016820210264996 0.15814139693975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>600638_2022_tava.laz</td>\n",
       "      <td>[POLYGON ((0.8100281070219353 0.38243363983929...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>600639_2022_tava.laz</td>\n",
       "      <td>[POLYGON ((0.654416550998576 0.836858185008168...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 laz_file                                           polygons\n",
       "0    397689_2023_tava.laz  [POLYGON ((0.2154821638250724 0.53317514155060...\n",
       "1    402642_2023_tava.laz  [POLYGON ((0.559215598856099 0.702996839769184...\n",
       "2    402674_2023_tava.laz  [POLYGON ((0.7066870752023533 0.31486295908689...\n",
       "3    407676_2023_tava.laz  [POLYGON ((0.6727867362787947 0.95630937255918...\n",
       "4    407700_2023_tava.laz  [POLYGON ((0.119291202398017 0.732177131809294...\n",
       "..                    ...                                                ...\n",
       "126  596650_2022_tava.laz  [POLYGON ((0.9488594959257171 0.22939210943877...\n",
       "127  596651_2022_tava.laz  [POLYGON ((-0.0511505041504279 0.2293921094387...\n",
       "128  598586_2022_tava.laz  [POLYGON ((0.2016820210264996 0.15814139693975...\n",
       "129  600638_2022_tava.laz  [POLYGON ((0.8100281070219353 0.38243363983929...\n",
       "130  600639_2022_tava.laz  [POLYGON ((0.654416550998576 0.836858185008168...\n",
       "\n",
       "[131 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<POLYGON ((0.215 0.533, 0.316 0.483, 0.343 0.417, 0.345 0.322, 0.314 0.254, ...>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0, 0.0) (1.0, 1.0, 1.0)\n",
      "[<POLYGON ((0.215 0.533, 0.316 0.483, 0.343 0.417, 0.345 0.322, 0.314 0.254, ...>]\n"
     ]
    }
   ],
   "source": [
    "display(normalized_polygons)\n",
    "test_poly = normalized_polygons['polygons'][0]\n",
    "display(test_poly)\n",
    "print((test_las.header.x_min, test_las.header.y_min, test_las.header.z_min), (test_las.header.x_max, test_las.header.y_max, test_las.header.z_max))\n",
    "print(test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4715859, 3) (4715859,)\n"
     ]
    }
   ],
   "source": [
    "xyz = test_las.xyz\n",
    "xyzc = np.hstack((xyz, test_las.points.array['classification'].reshape(-1, 1)))\n",
    "X = xyz\n",
    "y = (xyz[:, -1] == 12).astype(int)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = sk.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).cuda()  # If using GPU\n",
    "criterion = torch.nn.NLLLoss(weight=class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(X)\n",
    "y = torch.from_numpy(y).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PointCloudDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNet()\n",
    "pointnet.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(pointnet, criterion, train_loader, device, None, 10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpulocal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
