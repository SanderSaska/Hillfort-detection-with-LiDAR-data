{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hillfort detection with LiDAR data\n",
    "## Data management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "[Code](#code)\n",
    "\n",
    "1. [**Preparing data for training**](#preparing-data-for-training)\n",
    "2. [**Initializing and training the model**](#initializing-and-training-the-model)\n",
    "3. [**Evaluating the model**](#evaluating-the-model)\n",
    "4. [**Hyperparameter tuning**](#hyperparameter-tuning)\n",
    "5. [**Results**](#results)\n",
    "\n",
    "[End](#end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn numpy matplotlib laspy tqdm geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have GPU\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "# Otherwise\n",
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# Imports\n",
    "import os\n",
    "# import re\n",
    "# import csv\n",
    "# import typing\n",
    "import itertools\n",
    "# import json\n",
    "import logging\n",
    "import zipfile\n",
    "# import warnings\n",
    "# import evaluate\n",
    "# import types\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import torch\n",
    "# import math\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "import laspy # Reading LAS file format\n",
    "from tqdm import tqdm # Loading bars\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model setup has been copied from Nikita Karaev's Google Colab [PointNetClass](https://colab.research.google.com/github/nikitakaraevv/pointnet/blob/master/nbs/PointNetClass.ipynb#scrollTo=ZV20opgrv23I). Criterion has been customized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tnet(nn.Module):\n",
    "   def __init__(self, k=3):\n",
    "      super().__init__()\n",
    "      self.k=k\n",
    "      self.conv1 = nn.Conv1d(k,64,1)\n",
    "      self.conv2 = nn.Conv1d(64,128,1)\n",
    "      self.conv3 = nn.Conv1d(128,1024,1)\n",
    "      self.fc1 = nn.Linear(1024,512)\n",
    "      self.fc2 = nn.Linear(512,256)\n",
    "      self.fc3 = nn.Linear(256,k*k)\n",
    "\n",
    "      self.bn1 = nn.BatchNorm1d(64)\n",
    "      self.bn2 = nn.BatchNorm1d(128)\n",
    "      self.bn3 = nn.BatchNorm1d(1024)\n",
    "      self.bn4 = nn.BatchNorm1d(512)\n",
    "      self.bn5 = nn.BatchNorm1d(256)\n",
    "       \n",
    "\n",
    "   def forward(self, input):\n",
    "      # input.shape == (bs,n,3)\n",
    "      bs = input.size(0)\n",
    "      xb = F.relu(self.bn1(self.conv1(input)))\n",
    "      xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "      xb = F.relu(self.bn3(self.conv3(xb)))\n",
    "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "      flat = nn.Flatten(1)(pool)\n",
    "      xb = F.relu(self.bn4(self.fc1(flat)))\n",
    "      xb = F.relu(self.bn5(self.fc2(xb)))\n",
    "      \n",
    "      #initialize as identity\n",
    "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
    "      if xb.is_cuda:\n",
    "        init=init.cuda()\n",
    "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
    "      return matrix\n",
    "\n",
    "\n",
    "class Transform(nn.Module):\n",
    "   def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_transform = Tnet(k=3)\n",
    "        self.feature_transform = Tnet(k=64)\n",
    "        self.conv1 = nn.Conv1d(3,64,1)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64,128,1)\n",
    "        self.conv3 = nn.Conv1d(128,1024,1)\n",
    "       \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "       \n",
    "   def forward(self, input):\n",
    "        matrix3x3 = self.input_transform(input)\n",
    "        # batch matrix multiplication\n",
    "        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn1(self.conv1(xb)))\n",
    "\n",
    "        matrix64x64 = self.feature_transform(xb)\n",
    "        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n",
    "\n",
    "        xb = F.relu(self.bn2(self.conv2(xb)))\n",
    "        xb = self.bn3(self.conv3(xb))\n",
    "        xb = nn.MaxPool1d(xb.size(-1))(xb)\n",
    "        output = nn.Flatten(1)(xb)\n",
    "        return output, matrix3x3, matrix64x64\n",
    "\n",
    "class PointNet(nn.Module):\n",
    "    def __init__(self, classes = 10):\n",
    "        super().__init__()\n",
    "        self.transform = Transform()\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, classes)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        xb, matrix3x3, matrix64x64 = self.transform(input)\n",
    "        xb = F.relu(self.bn1(self.fc1(xb)))\n",
    "        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n",
    "        output = self.fc3(xb)\n",
    "        return self.logsoftmax(output), matrix3x3, matrix64x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointCloudDataset(Dataset):\n",
    "    def __init__(self, xyz, labels, num_points=1024):\n",
    "        self.xyz = xyz\n",
    "        self.labels = labels\n",
    "        self.num_points = num_points\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xyz)  # Number of point clouds in the dataset\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        points = self.xyz[idx]  # Points for the idx-th sample\n",
    "        labels = self.labels[idx]  # Labels for the same sample\n",
    "        \n",
    "        # Ensure points is a 2D tensor with shape (N, 3)\n",
    "        if points.ndimension() == 1:\n",
    "            points = points.view(-1, 3)\n",
    "\n",
    "        # Padding to ensure every point cloud has num_points\n",
    "        if points.shape[0] < self.num_points:\n",
    "            padding = torch.zeros(self.num_points - points.shape[0], 3)  # Padding with zeros\n",
    "            points = torch.cat([points, padding], dim=0)  # Concatenate the points with the padding\n",
    "        else:\n",
    "            points = points[:self.num_points]  # Truncate if there are more than num_points\n",
    "\n",
    "        return {'pointcloud': points, 'category': labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointnetloss(outputs, labels, m3x3, m64x64, criterion, m3x3_weight=0.0001, m64x64_weight=0.0001):\n",
    "    if not criterion:\n",
    "        criterion = torch.nn.NLLLoss()\n",
    "    bs = outputs.size(0)\n",
    "\n",
    "    # Identity matrices for regularization (to penalize transformation deviations)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs, 1, 1).to(outputs.device)\n",
    "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs, 1, 1).to(outputs.device)\n",
    "\n",
    "    # Regularization terms\n",
    "    diff3x3 = id3x3 - torch.bmm(m3x3, m3x3.transpose(1, 2))\n",
    "    diff64x64 = id64x64 - torch.bmm(m64x64, m64x64.transpose(1, 2))\n",
    "\n",
    "    # Compute the base loss (negative log likelihood)\n",
    "    base_loss = criterion(outputs, labels)\n",
    "\n",
    "    # Add regularization (transformation matrices)\n",
    "    reg_loss = m3x3_weight * (torch.norm(diff3x3) + torch.norm(diff64x64)) / float(bs)\n",
    "\n",
    "    return base_loss + reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pointnet, criterion, train_loader, device, val_loader=None, epochs=15, save=True, save_location_dir='../model_weights/'):\n",
    "    optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.001)\n",
    "    for epoch in range(epochs): \n",
    "        pointnet.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
    "\n",
    "            loss = pointnetloss(outputs, labels, m3x3, m64x64, criterion)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 9:    # print every 10 mini-batches\n",
    "                    print('[Epoch: %d, Batch: %4d / %4d], loss: %.3f' %\n",
    "                        (epoch + 1, i + 1, len(train_loader), running_loss / 10))\n",
    "                    running_loss = 0.0\n",
    "\n",
    "        pointnet.eval()\n",
    "        correct = total = 0\n",
    "\n",
    "        # validation\n",
    "        if val_loader:\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data['pointcloud'].to(device).float(), data['category'].to(device)\n",
    "                    outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            val_acc = 100. * correct / total\n",
    "            print('Valid accuracy: %d %%' % val_acc)\n",
    "\n",
    "        # save the model\n",
    "        if save:\n",
    "            print(\"Saving model\")\n",
    "            torch.save(pointnet.state_dict(), f=os.path.join(save_location_dir, f'save_epoch_{str(epoch)}.pth')) # Save the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_and_y(laz_file_dir = '../data/downsampled_class_lazFiles/'):\n",
    "\n",
    "    # Step 1: Get the list of LiDAR files\n",
    "    all_files = [os.path.join(laz_file_dir, f) for f in os.listdir(laz_file_dir) if f.endswith('.laz')]\n",
    "\n",
    "    # Step 2: Split the files into train, validation, and test sets\n",
    "    train_files, test_files = sk.model_selection.train_test_split(all_files, test_size=0.2, random_state=42)  # 20% for testing\n",
    "    train_files, val_files = sk.model_selection.train_test_split(train_files, test_size=0.1, random_state=42)  # 10% of train for validation\n",
    "\n",
    "    print(f\"Number of files - Train: {len(train_files)}, Validation: {len(val_files)}, Test: {len(test_files)}\")\n",
    "\n",
    "    # Step 3: Load and group data based on the splits\n",
    "    def load_grouped_data(file_list):\n",
    "        X, y = [], []\n",
    "        for file in file_list:\n",
    "            las = laspy.read(file)\n",
    "            xyz = las.xyz\n",
    "            labels = (las.points.array['classification'] == 12).astype(int)  # Hillfort class\n",
    "            X.append(xyz)\n",
    "            y.append(labels)\n",
    "        return X, y\n",
    "\n",
    "    # Load data for each split\n",
    "    X_train, y_train = load_grouped_data(train_files)\n",
    "    X_val, y_val = load_grouped_data(val_files)\n",
    "    X_test, y_test = load_grouped_data(test_files)\n",
    "\n",
    "    # Optionally, combine all points into single arrays for each split\n",
    "    X_train_combined = np.vstack(X_train)\n",
    "    y_train_combined = np.concatenate(y_train)\n",
    "\n",
    "    X_val_combined = np.vstack(X_val)\n",
    "    y_val_combined = np.concatenate(y_val)\n",
    "\n",
    "    X_test_combined = np.vstack(X_test)\n",
    "    y_test_combined = np.concatenate(y_test)\n",
    "\n",
    "    # Print final shapes\n",
    "    print(\"Train data shape:\", X_train_combined.shape, y_train_combined.shape)\n",
    "    print(\"Validation data shape:\", X_val_combined.shape, y_val_combined.shape)\n",
    "    print(\"Test data shape:\", X_test_combined.shape, y_test_combined.shape)\n",
    "    \n",
    "    return X_train_combined, y_train_combined, X_val_combined, y_val_combined, X_test_combined, y_test_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should the model use CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training, validation and testing data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz_file_dir = '../data/downsampled_class_lazFiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files - Train: 93, Validation: 11, Test: 27\n",
      "Train data shape: (7141350, 3) (7141350,)\n",
      "Validation data shape: (731420, 3) (731420,)\n",
      "Test data shape: (1945993, 3) (1945993,)\n"
     ]
    }
   ],
   "source": [
    "X_train_combined, y_train_combined, X_val_combined, y_val_combined, X_test_combined, y_test_combined = prepare_X_and_y(laz_file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does `y` have both classes for each set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train_combined))\n",
    "print(np.unique(y_val_combined))\n",
    "print(np.unique(y_test_combined))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating criterion that adds more weight to the undersampled class, which is hillforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51037648 24.59294998]\n"
     ]
    }
   ],
   "source": [
    "class_weights = sk.utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train_combined), y=y_train_combined)\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).cuda() if device.type == \"cuda\" else torch.tensor(class_weights, dtype=torch.float32)\n",
    "criterion = torch.nn.NLLLoss(weight=class_weights_tensor)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.from_numpy(X_train_combined)\n",
    "train_y = torch.from_numpy(y_train_combined).long()\n",
    "val_X = torch.from_numpy(X_val_combined)\n",
    "val_y = torch.from_numpy(y_val_combined).long()\n",
    "test_X = torch.from_numpy(X_test_combined)\n",
    "test_y = torch.from_numpy(y_test_combined).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up splits for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PointCloudDataset(train_X, train_y)\n",
    "val_dataset = PointCloudDataset(val_X, val_y)\n",
    "test_dataset = PointCloudDataset(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing and training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model weights save directory and initializing PointNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_dir = '../model_weights_pointnet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointnet = PointNet(classes=2)\n",
    "pointnet.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training PointNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1, Batch:   10 / 55793], loss: 0.700\n",
      "[Epoch: 1, Batch:   20 / 55793], loss: 0.676\n",
      "[Epoch: 1, Batch:   30 / 55793], loss: 0.770\n",
      "[Epoch: 1, Batch:   40 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch:   50 / 55793], loss: 0.706\n",
      "[Epoch: 1, Batch:   60 / 55793], loss: 0.664\n",
      "[Epoch: 1, Batch:   70 / 55793], loss: 0.700\n",
      "[Epoch: 1, Batch:   80 / 55793], loss: 0.724\n",
      "[Epoch: 1, Batch:   90 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch:  100 / 55793], loss: 0.698\n",
      "[Epoch: 1, Batch:  110 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch:  120 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch:  130 / 55793], loss: 0.713\n",
      "[Epoch: 1, Batch:  140 / 55793], loss: 0.723\n",
      "[Epoch: 1, Batch:  150 / 55793], loss: 0.703\n",
      "[Epoch: 1, Batch:  160 / 55793], loss: 0.690\n",
      "[Epoch: 1, Batch:  170 / 55793], loss: 0.737\n",
      "[Epoch: 1, Batch:  180 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch:  190 / 55793], loss: 0.691\n",
      "[Epoch: 1, Batch:  200 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch:  210 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch:  220 / 55793], loss: 0.714\n",
      "[Epoch: 1, Batch:  230 / 55793], loss: 0.721\n",
      "[Epoch: 1, Batch:  240 / 55793], loss: 0.703\n",
      "[Epoch: 1, Batch:  250 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch:  260 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch:  270 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch:  280 / 55793], loss: 0.665\n",
      "[Epoch: 1, Batch:  290 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch:  300 / 55793], loss: 0.699\n",
      "[Epoch: 1, Batch:  310 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch:  320 / 55793], loss: 0.706\n",
      "[Epoch: 1, Batch:  330 / 55793], loss: 0.711\n",
      "[Epoch: 1, Batch:  340 / 55793], loss: 0.713\n",
      "[Epoch: 1, Batch:  350 / 55793], loss: 0.698\n",
      "[Epoch: 1, Batch:  360 / 55793], loss: 0.721\n",
      "[Epoch: 1, Batch:  370 / 55793], loss: 0.709\n",
      "[Epoch: 1, Batch:  380 / 55793], loss: 0.699\n",
      "[Epoch: 1, Batch:  390 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch:  400 / 55793], loss: 0.687\n",
      "[Epoch: 1, Batch:  410 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch:  420 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch:  430 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch:  440 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch:  450 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch:  460 / 55793], loss: 0.694\n",
      "[Epoch: 1, Batch:  470 / 55793], loss: 0.724\n",
      "[Epoch: 1, Batch:  480 / 55793], loss: 0.696\n",
      "[Epoch: 1, Batch:  490 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch:  500 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch:  510 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch:  520 / 55793], loss: 0.706\n",
      "[Epoch: 1, Batch:  530 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch:  540 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch:  550 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch:  560 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch:  570 / 55793], loss: 0.676\n",
      "[Epoch: 1, Batch:  580 / 55793], loss: 0.739\n",
      "[Epoch: 1, Batch:  590 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch:  600 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch:  610 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch:  620 / 55793], loss: 0.858\n",
      "[Epoch: 1, Batch:  630 / 55793], loss: 0.743\n",
      "[Epoch: 1, Batch:  640 / 55793], loss: 0.730\n",
      "[Epoch: 1, Batch:  650 / 55793], loss: 0.717\n",
      "[Epoch: 1, Batch:  660 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch:  670 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch:  680 / 55793], loss: 0.798\n",
      "[Epoch: 1, Batch:  690 / 55793], loss: 0.685\n",
      "[Epoch: 1, Batch:  700 / 55793], loss: 0.722\n",
      "[Epoch: 1, Batch:  710 / 55793], loss: 0.685\n",
      "[Epoch: 1, Batch:  720 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch:  730 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch:  740 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch:  750 / 55793], loss: 0.809\n",
      "[Epoch: 1, Batch:  760 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch:  770 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch:  780 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch:  790 / 55793], loss: 0.704\n",
      "[Epoch: 1, Batch:  800 / 55793], loss: 0.685\n",
      "[Epoch: 1, Batch:  810 / 55793], loss: 0.732\n",
      "[Epoch: 1, Batch:  820 / 55793], loss: 0.720\n",
      "[Epoch: 1, Batch:  830 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch:  840 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch:  850 / 55793], loss: 0.711\n",
      "[Epoch: 1, Batch:  860 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch:  870 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch:  880 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch:  890 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch:  900 / 55793], loss: 0.709\n",
      "[Epoch: 1, Batch:  910 / 55793], loss: 0.706\n",
      "[Epoch: 1, Batch:  920 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch:  930 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch:  940 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch:  950 / 55793], loss: 0.693\n",
      "[Epoch: 1, Batch:  960 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch:  970 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch:  980 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch:  990 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 1000 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 1010 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 1020 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 1030 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 1040 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 1050 / 55793], loss: 0.669\n",
      "[Epoch: 1, Batch: 1060 / 55793], loss: 0.676\n",
      "[Epoch: 1, Batch: 1070 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 1080 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 1090 / 55793], loss: 0.692\n",
      "[Epoch: 1, Batch: 1100 / 55793], loss: 0.694\n",
      "[Epoch: 1, Batch: 1110 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 1120 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 1130 / 55793], loss: 0.665\n",
      "[Epoch: 1, Batch: 1140 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 1150 / 55793], loss: 0.731\n",
      "[Epoch: 1, Batch: 1160 / 55793], loss: 0.744\n",
      "[Epoch: 1, Batch: 1170 / 55793], loss: 0.690\n",
      "[Epoch: 1, Batch: 1180 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 1190 / 55793], loss: 0.700\n",
      "[Epoch: 1, Batch: 1200 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 1210 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 1220 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 1230 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 1240 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 1250 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 1260 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 1270 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 1280 / 55793], loss: 0.699\n",
      "[Epoch: 1, Batch: 1290 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 1300 / 55793], loss: 0.663\n",
      "[Epoch: 1, Batch: 1310 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 1320 / 55793], loss: 0.720\n",
      "[Epoch: 1, Batch: 1330 / 55793], loss: 0.705\n",
      "[Epoch: 1, Batch: 1340 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 1350 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 1360 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 1370 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch: 1380 / 55793], loss: 0.759\n",
      "[Epoch: 1, Batch: 1390 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 1400 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 1410 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 1420 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 1430 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 1440 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 1450 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 1460 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 1470 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 1480 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 1490 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 1500 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 1510 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 1520 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 1530 / 55793], loss: 0.686\n",
      "[Epoch: 1, Batch: 1540 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 1550 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 1560 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 1570 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 1580 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 1590 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 1600 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 1610 / 55793], loss: 0.697\n",
      "[Epoch: 1, Batch: 1620 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 1630 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 1640 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 1650 / 55793], loss: 0.700\n",
      "[Epoch: 1, Batch: 1660 / 55793], loss: 0.693\n",
      "[Epoch: 1, Batch: 1670 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 1680 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 1690 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 1700 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 1710 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch: 1720 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 1730 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 1740 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 1750 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 1760 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 1770 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 1780 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 1790 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 1800 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 1810 / 55793], loss: 0.713\n",
      "[Epoch: 1, Batch: 1820 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 1830 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 1840 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 1850 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 1860 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 1870 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 1880 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 1890 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 1900 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 1910 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 1920 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 1930 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 1940 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 1950 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 1960 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 1970 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 1980 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 1990 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 2000 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 2010 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 2020 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 2030 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 2040 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 2050 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 2060 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 2070 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 2080 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 2090 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 2100 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 2110 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 2120 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 2130 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 2140 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 2150 / 55793], loss: 0.684\n",
      "[Epoch: 1, Batch: 2160 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 2170 / 55793], loss: 0.704\n",
      "[Epoch: 1, Batch: 2180 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 2190 / 55793], loss: 0.663\n",
      "[Epoch: 1, Batch: 2200 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 2210 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 2220 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 2230 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 2240 / 55793], loss: 0.694\n",
      "[Epoch: 1, Batch: 2250 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 2260 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 2270 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch: 2280 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 2290 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 2300 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 2310 / 55793], loss: 0.693\n",
      "[Epoch: 1, Batch: 2320 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch: 2330 / 55793], loss: 0.672\n",
      "[Epoch: 1, Batch: 2340 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 2350 / 55793], loss: 0.695\n",
      "[Epoch: 1, Batch: 2360 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 2370 / 55793], loss: 0.714\n",
      "[Epoch: 1, Batch: 2380 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 2390 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 2400 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 2410 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 2420 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 2430 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 2440 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 2450 / 55793], loss: 0.665\n",
      "[Epoch: 1, Batch: 2460 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 2470 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 2480 / 55793], loss: 0.689\n",
      "[Epoch: 1, Batch: 2490 / 55793], loss: 0.672\n",
      "[Epoch: 1, Batch: 2500 / 55793], loss: 0.697\n",
      "[Epoch: 1, Batch: 2510 / 55793], loss: 0.700\n",
      "[Epoch: 1, Batch: 2520 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 2530 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 2540 / 55793], loss: 0.704\n",
      "[Epoch: 1, Batch: 2550 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 2560 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 2570 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 2580 / 55793], loss: 0.700\n",
      "[Epoch: 1, Batch: 2590 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 2600 / 55793], loss: 0.788\n",
      "[Epoch: 1, Batch: 2610 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 2620 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 2630 / 55793], loss: 0.714\n",
      "[Epoch: 1, Batch: 2640 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 2650 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 2660 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 2670 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 2680 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 2690 / 55793], loss: 0.699\n",
      "[Epoch: 1, Batch: 2700 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 2710 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 2720 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 2730 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 2740 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 2750 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 2760 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 2770 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 2780 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 2790 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 2800 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 2810 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 2820 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 2830 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 2840 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 2850 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 2860 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 2870 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 2880 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 2890 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 2900 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 2910 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 2920 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 2930 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 2940 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 2950 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 2960 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 2970 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch: 2980 / 55793], loss: 0.664\n",
      "[Epoch: 1, Batch: 2990 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 3000 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 3010 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 3020 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 3030 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 3040 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 3050 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 3060 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 3070 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 3080 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 3090 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 3100 / 55793], loss: 0.684\n",
      "[Epoch: 1, Batch: 3110 / 55793], loss: 0.703\n",
      "[Epoch: 1, Batch: 3120 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 3130 / 55793], loss: 0.727\n",
      "[Epoch: 1, Batch: 3140 / 55793], loss: 0.711\n",
      "[Epoch: 1, Batch: 3150 / 55793], loss: 0.761\n",
      "[Epoch: 1, Batch: 3160 / 55793], loss: 0.712\n",
      "[Epoch: 1, Batch: 3170 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch: 3180 / 55793], loss: 0.692\n",
      "[Epoch: 1, Batch: 3190 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch: 3200 / 55793], loss: 0.750\n",
      "[Epoch: 1, Batch: 3210 / 55793], loss: 0.704\n",
      "[Epoch: 1, Batch: 3220 / 55793], loss: 0.676\n",
      "[Epoch: 1, Batch: 3230 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 3240 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 3250 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 3260 / 55793], loss: 0.718\n",
      "[Epoch: 1, Batch: 3270 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 3280 / 55793], loss: 0.657\n",
      "[Epoch: 1, Batch: 3290 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 3300 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 3310 / 55793], loss: 0.657\n",
      "[Epoch: 1, Batch: 3320 / 55793], loss: 0.741\n",
      "[Epoch: 1, Batch: 3330 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 3340 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 3350 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 3360 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 3370 / 55793], loss: 0.774\n",
      "[Epoch: 1, Batch: 3380 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 3390 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 3400 / 55793], loss: 0.657\n",
      "[Epoch: 1, Batch: 3410 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 3420 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 3430 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 3440 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 3450 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 3460 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 3470 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 3480 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 3490 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 3500 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 3510 / 55793], loss: 0.705\n",
      "[Epoch: 1, Batch: 3520 / 55793], loss: 0.664\n",
      "[Epoch: 1, Batch: 3530 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 3540 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 3550 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 3560 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 3570 / 55793], loss: 0.709\n",
      "[Epoch: 1, Batch: 3580 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 3590 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 3600 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 3610 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 3620 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 3630 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 3640 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 3650 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 3660 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 3670 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 3680 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch: 3690 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 3700 / 55793], loss: 0.701\n",
      "[Epoch: 1, Batch: 3710 / 55793], loss: 0.692\n",
      "[Epoch: 1, Batch: 3720 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 3730 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 3740 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 3750 / 55793], loss: 0.737\n",
      "[Epoch: 1, Batch: 3760 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 3770 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 3780 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 3790 / 55793], loss: 0.698\n",
      "[Epoch: 1, Batch: 3800 / 55793], loss: 0.669\n",
      "[Epoch: 1, Batch: 3810 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 3820 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 3830 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 3840 / 55793], loss: 0.709\n",
      "[Epoch: 1, Batch: 3850 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 3860 / 55793], loss: 0.694\n",
      "[Epoch: 1, Batch: 3870 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 3880 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 3890 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 3900 / 55793], loss: 0.735\n",
      "[Epoch: 1, Batch: 3910 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 3920 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 3930 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch: 3940 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 3950 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 3960 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 3970 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 3980 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 3990 / 55793], loss: 0.672\n",
      "[Epoch: 1, Batch: 4000 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch: 4010 / 55793], loss: 0.657\n",
      "[Epoch: 1, Batch: 4020 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 4030 / 55793], loss: 0.669\n",
      "[Epoch: 1, Batch: 4040 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 4050 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 4060 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 4070 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 4080 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 4090 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 4100 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 4110 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 4120 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 4130 / 55793], loss: 0.690\n",
      "[Epoch: 1, Batch: 4140 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 4150 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 4160 / 55793], loss: 0.705\n",
      "[Epoch: 1, Batch: 4170 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 4180 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 4190 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 4200 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 4210 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch: 4220 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 4230 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 4240 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 4250 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 4260 / 55793], loss: 0.678\n",
      "[Epoch: 1, Batch: 4270 / 55793], loss: 0.676\n",
      "[Epoch: 1, Batch: 4280 / 55793], loss: 0.696\n",
      "[Epoch: 1, Batch: 4290 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 4300 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 4310 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 4320 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 4330 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 4340 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 4350 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch: 4360 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 4370 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 4380 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 4390 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 4400 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 4410 / 55793], loss: 0.707\n",
      "[Epoch: 1, Batch: 4420 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch: 4430 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 4440 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 4450 / 55793], loss: 0.684\n",
      "[Epoch: 1, Batch: 4460 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 4470 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 4480 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 4490 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 4500 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 4510 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 4520 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 4530 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 4540 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 4550 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 4560 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 4570 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 4580 / 55793], loss: 0.676\n",
      "[Epoch: 1, Batch: 4590 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 4600 / 55793], loss: 0.703\n",
      "[Epoch: 1, Batch: 4610 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 4620 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 4630 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 4640 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 4650 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 4660 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch: 4670 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 4680 / 55793], loss: 0.768\n",
      "[Epoch: 1, Batch: 4690 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 4700 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 4710 / 55793], loss: 0.669\n",
      "[Epoch: 1, Batch: 4720 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 4730 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 4740 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 4750 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 4760 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 4770 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 4780 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 4790 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 4800 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 4810 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 4820 / 55793], loss: 0.704\n",
      "[Epoch: 1, Batch: 4830 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 4840 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 4850 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 4860 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 4870 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 4880 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 4890 / 55793], loss: 0.724\n",
      "[Epoch: 1, Batch: 4900 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 4910 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 4920 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 4930 / 55793], loss: 0.695\n",
      "[Epoch: 1, Batch: 4940 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 4950 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 4960 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 4970 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 4980 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 4990 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 5000 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 5010 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 5020 / 55793], loss: 0.691\n",
      "[Epoch: 1, Batch: 5030 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 5040 / 55793], loss: 0.708\n",
      "[Epoch: 1, Batch: 5050 / 55793], loss: 0.665\n",
      "[Epoch: 1, Batch: 5060 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 5070 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 5080 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 5090 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 5100 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 5110 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 5120 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 5130 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 5140 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 5150 / 55793], loss: 0.694\n",
      "[Epoch: 1, Batch: 5160 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 5170 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 5180 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 5190 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 5200 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 5210 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 5220 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 5230 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 5240 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 5250 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 5260 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 5270 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 5280 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 5290 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 5300 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 5310 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 5320 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 5330 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 5340 / 55793], loss: 0.698\n",
      "[Epoch: 1, Batch: 5350 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 5360 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 5370 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 5380 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 5390 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 5400 / 55793], loss: 0.678\n",
      "[Epoch: 1, Batch: 5410 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 5420 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 5430 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 5440 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 5450 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 5460 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 5470 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 5480 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 5490 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 5500 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 5510 / 55793], loss: 0.690\n",
      "[Epoch: 1, Batch: 5520 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 5530 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 5540 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 5550 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 5560 / 55793], loss: 0.678\n",
      "[Epoch: 1, Batch: 5570 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 5580 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 5590 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 5600 / 55793], loss: 0.663\n",
      "[Epoch: 1, Batch: 5610 / 55793], loss: 0.690\n",
      "[Epoch: 1, Batch: 5620 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 5630 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 5640 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 5650 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 5660 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 5670 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 5680 / 55793], loss: 0.705\n",
      "[Epoch: 1, Batch: 5690 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 5700 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 5710 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 5720 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 5730 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 5740 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 5750 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 5760 / 55793], loss: 0.657\n",
      "[Epoch: 1, Batch: 5770 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 5780 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 5790 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 5800 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 5810 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 5820 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 5830 / 55793], loss: 0.687\n",
      "[Epoch: 1, Batch: 5840 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 5850 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 5860 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 5870 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 5880 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 5890 / 55793], loss: 0.690\n",
      "[Epoch: 1, Batch: 5900 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 5910 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 5920 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 5930 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 5940 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 5950 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 5960 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 5970 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 5980 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch: 5990 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 6000 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 6010 / 55793], loss: 0.672\n",
      "[Epoch: 1, Batch: 6020 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 6030 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 6040 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 6050 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 6060 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 6070 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 6080 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 6090 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 6100 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 6110 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 6120 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 6130 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 6140 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 6150 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 6160 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 6170 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 6180 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 6190 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 6200 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 6210 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 6220 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 6230 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 6240 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 6250 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 6260 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 6270 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 6280 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 6290 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 6300 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 6310 / 55793], loss: 0.772\n",
      "[Epoch: 1, Batch: 6320 / 55793], loss: 0.698\n",
      "[Epoch: 1, Batch: 6330 / 55793], loss: 0.693\n",
      "[Epoch: 1, Batch: 6340 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch: 6350 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 6360 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch: 6370 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch: 6380 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 6390 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 6400 / 55793], loss: 0.663\n",
      "[Epoch: 1, Batch: 6410 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 6420 / 55793], loss: 0.745\n",
      "[Epoch: 1, Batch: 6430 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 6440 / 55793], loss: 0.696\n",
      "[Epoch: 1, Batch: 6450 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 6460 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 6470 / 55793], loss: 0.699\n",
      "[Epoch: 1, Batch: 6480 / 55793], loss: 0.690\n",
      "[Epoch: 1, Batch: 6490 / 55793], loss: 0.664\n",
      "[Epoch: 1, Batch: 6500 / 55793], loss: 0.665\n",
      "[Epoch: 1, Batch: 6510 / 55793], loss: 0.665\n",
      "[Epoch: 1, Batch: 6520 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 6530 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 6540 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 6550 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 6560 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 6570 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 6580 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 6590 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 6600 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 6610 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 6620 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 6630 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 6640 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 6650 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 6660 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 6670 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 6680 / 55793], loss: 0.684\n",
      "[Epoch: 1, Batch: 6690 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 6700 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 6710 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 6720 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 6730 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 6740 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 6750 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 6760 / 55793], loss: 0.762\n",
      "[Epoch: 1, Batch: 6770 / 55793], loss: 0.691\n",
      "[Epoch: 1, Batch: 6780 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 6790 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 6800 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 6810 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 6820 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 6830 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 6840 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 6850 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 6860 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 6870 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 6880 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 6890 / 55793], loss: 0.701\n",
      "[Epoch: 1, Batch: 6900 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 6910 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 6920 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 6930 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 6940 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 6950 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 6960 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 6970 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 6980 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 6990 / 55793], loss: 0.693\n",
      "[Epoch: 1, Batch: 7000 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 7010 / 55793], loss: 0.689\n",
      "[Epoch: 1, Batch: 7020 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 7030 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 7040 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 7050 / 55793], loss: 0.719\n",
      "[Epoch: 1, Batch: 7060 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 7070 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 7080 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 7090 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 7100 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch: 7110 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 7120 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 7130 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 7140 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 7150 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 7160 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 7170 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 7180 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 7190 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 7200 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 7210 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 7220 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 7230 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 7240 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 7250 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 7260 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 7270 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 7280 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 7290 / 55793], loss: 0.712\n",
      "[Epoch: 1, Batch: 7300 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 7310 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 7320 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 7330 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 7340 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 7350 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 7360 / 55793], loss: 0.687\n",
      "[Epoch: 1, Batch: 7370 / 55793], loss: 0.690\n",
      "[Epoch: 1, Batch: 7380 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 7390 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 7400 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 7410 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 7420 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 7430 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 7440 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 7450 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 7460 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 7470 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 7480 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 7490 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 7500 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 7510 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 7520 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 7530 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 7540 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch: 7550 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 7560 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 7570 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 7580 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 7590 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 7600 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 7610 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 7620 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 7630 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 7640 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 7650 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 7660 / 55793], loss: 0.697\n",
      "[Epoch: 1, Batch: 7670 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 7680 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 7690 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 7700 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 7710 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 7720 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 7730 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 7740 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 7750 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 7760 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 7770 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 7780 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 7790 / 55793], loss: 0.665\n",
      "[Epoch: 1, Batch: 7800 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 7810 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 7820 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 7830 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 7840 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 7850 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 7860 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 7870 / 55793], loss: 0.746\n",
      "[Epoch: 1, Batch: 7880 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 7890 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 7900 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 7910 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 7920 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 7930 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 7940 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 7950 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 7960 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 7970 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 7980 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 7990 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 8000 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 8010 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 8020 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 8030 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 8040 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 8050 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 8060 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 8070 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 8080 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 8090 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 8100 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 8110 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 8120 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 8130 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 8140 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 8150 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 8160 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 8170 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 8180 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch: 8190 / 55793], loss: 0.676\n",
      "[Epoch: 1, Batch: 8200 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 8210 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 8220 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 8230 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 8240 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 8250 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 8260 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 8270 / 55793], loss: 0.712\n",
      "[Epoch: 1, Batch: 8280 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 8290 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 8300 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 8310 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 8320 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 8330 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 8340 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 8350 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 8360 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 8370 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 8380 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 8390 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 8400 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 8410 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 8420 / 55793], loss: 0.663\n",
      "[Epoch: 1, Batch: 8430 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 8440 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 8450 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 8460 / 55793], loss: 0.723\n",
      "[Epoch: 1, Batch: 8470 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 8480 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 8490 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 8500 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 8510 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 8520 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 8530 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 8540 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 8550 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 8560 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 8570 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 8580 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 8590 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 8600 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 8610 / 55793], loss: 0.675\n",
      "[Epoch: 1, Batch: 8620 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 8630 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 8640 / 55793], loss: 0.665\n",
      "[Epoch: 1, Batch: 8650 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 8660 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 8670 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 8680 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 8690 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 8700 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 8710 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 8720 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 8730 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 8740 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch: 8750 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 8760 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 8770 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 8780 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 8790 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 8800 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 8810 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 8820 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 8830 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 8840 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 8850 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 8860 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 8870 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 8880 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 8890 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 8900 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 8910 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 8920 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 8930 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 8940 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 8950 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 8960 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 8970 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 8980 / 55793], loss: 0.715\n",
      "[Epoch: 1, Batch: 8990 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 9000 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 9010 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 9020 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 9030 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 9040 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 9050 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 9060 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 9070 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 9080 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 9090 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 9100 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 9110 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 9120 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 9130 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 9140 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 9150 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 9160 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 9170 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 9180 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 9190 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 9200 / 55793], loss: 0.694\n",
      "[Epoch: 1, Batch: 9210 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 9220 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 9230 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 9240 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 9250 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 9260 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 9270 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 9280 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 9290 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 9300 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 9310 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 9320 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 9330 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 9340 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 9350 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 9360 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 9370 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 9380 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 9390 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 9400 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 9410 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 9420 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 9430 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 9440 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 9450 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 9460 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 9470 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 9480 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 9490 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 9500 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 9510 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 9520 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 9530 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 9540 / 55793], loss: 0.687\n",
      "[Epoch: 1, Batch: 9550 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 9560 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 9570 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 9580 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 9590 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 9600 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 9610 / 55793], loss: 0.663\n",
      "[Epoch: 1, Batch: 9620 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 9630 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 9640 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 9650 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 9660 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 9670 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 9680 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 9690 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 9700 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 9710 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 9720 / 55793], loss: 0.697\n",
      "[Epoch: 1, Batch: 9730 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 9740 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 9750 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 9760 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 9770 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 9780 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 9790 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 9800 / 55793], loss: 0.687\n",
      "[Epoch: 1, Batch: 9810 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 9820 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 9830 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 9840 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 9850 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 9860 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 9870 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 9880 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 9890 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 9900 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 9910 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 9920 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 9930 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 9940 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 9950 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 9960 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 9970 / 55793], loss: 0.664\n",
      "[Epoch: 1, Batch: 9980 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 9990 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 10000 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 10010 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 10020 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 10030 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 10040 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 10050 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 10060 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 10070 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 10080 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 10090 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 10100 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 10110 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 10120 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 10130 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 10140 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 10150 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 10160 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 10170 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 10180 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 10190 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 10200 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 10210 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 10220 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 10230 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 10240 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 10250 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 10260 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 10270 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 10280 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 10290 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 10300 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 10310 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 10320 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 10330 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 10340 / 55793], loss: 0.702\n",
      "[Epoch: 1, Batch: 10350 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 10360 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 10370 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 10380 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 10390 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 10400 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 10410 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 10420 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 10430 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 10440 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 10450 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 10460 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 10470 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 10480 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 10490 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 10500 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 10510 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 10520 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 10530 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 10540 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 10550 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 10560 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 10570 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 10580 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 10590 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 10600 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 10610 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 10620 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 10630 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 10640 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 10650 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 10660 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 10670 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 10680 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 10690 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 10700 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 10710 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 10720 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 10730 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 10740 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 10750 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 10760 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 10770 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 10780 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 10790 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 10800 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 10810 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 10820 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 10830 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 10840 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 10850 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 10860 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 10870 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 10880 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 10890 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 10900 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 10910 / 55793], loss: 0.672\n",
      "[Epoch: 1, Batch: 10920 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 10930 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 10940 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 10950 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 10960 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 10970 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 10980 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 10990 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 11000 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 11010 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 11020 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 11030 / 55793], loss: 0.699\n",
      "[Epoch: 1, Batch: 11040 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 11050 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 11060 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 11070 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 11080 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 11090 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 11100 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 11110 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 11120 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 11130 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 11140 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 11150 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 11160 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 11170 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 11180 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 11190 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 11200 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 11210 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 11220 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 11230 / 55793], loss: 0.685\n",
      "[Epoch: 1, Batch: 11240 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 11250 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 11260 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 11270 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 11280 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 11290 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 11300 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 11310 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 11320 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 11330 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 11340 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 11350 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 11360 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch: 11370 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 11380 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 11390 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 11400 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 11410 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 11420 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 11430 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 11440 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 11450 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 11460 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 11470 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 11480 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 11490 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 11500 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 11510 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 11520 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 11530 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 11540 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 11550 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 11560 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 11570 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 11580 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 11590 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 11600 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 11610 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 11620 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 11630 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 11640 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 11650 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 11660 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 11670 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 11680 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 11690 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 11700 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 11710 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 11720 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 11730 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 11740 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 11750 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 11760 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 11770 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 11780 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 11790 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 11800 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 11810 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 11820 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 11830 / 55793], loss: 0.673\n",
      "[Epoch: 1, Batch: 11840 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 11850 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 11860 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 11870 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 11880 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 11890 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 11900 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 11910 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 11920 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 11930 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 11940 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 11950 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 11960 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 11970 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 11980 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 11990 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 12000 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 12010 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 12020 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 12030 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 12040 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 12050 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 12060 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 12070 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 12080 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 12090 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 12100 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 12110 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 12120 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 12130 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 12140 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 12150 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 12160 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 12170 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 12180 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 12190 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 12200 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 12210 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 12220 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 12230 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 12240 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 12250 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 12260 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 12270 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 12280 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 12290 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 12300 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 12310 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 12320 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 12330 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 12340 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 12350 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 12360 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 12370 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 12380 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 12390 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 12400 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 12410 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 12420 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 12430 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 12440 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 12450 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 12460 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 12470 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 12480 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 12490 / 55793], loss: 0.686\n",
      "[Epoch: 1, Batch: 12500 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 12510 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 12520 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 12530 / 55793], loss: 0.691\n",
      "[Epoch: 1, Batch: 12540 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 12550 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 12560 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 12570 / 55793], loss: 0.727\n",
      "[Epoch: 1, Batch: 12580 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 12590 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 12600 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 12610 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 12620 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 12630 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 12640 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 12650 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 12660 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 12670 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 12680 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 12690 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 12700 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 12710 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 12720 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 12730 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 12740 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 12750 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 12760 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 12770 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 12780 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 12790 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 12800 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 12810 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 12820 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 12830 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 12840 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 12850 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 12860 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 12870 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 12880 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 12890 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 12900 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 12910 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 12920 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 12930 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 12940 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 12950 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 12960 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 12970 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 12980 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 12990 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 13000 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 13010 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 13020 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 13030 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 13040 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 13050 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 13060 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 13070 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 13080 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 13090 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 13100 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 13110 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 13120 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 13130 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 13140 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 13150 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 13160 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 13170 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 13180 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 13190 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 13200 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 13210 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 13220 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 13230 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 13240 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 13250 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 13260 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 13270 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 13280 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 13290 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 13300 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 13310 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 13320 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 13330 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 13340 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 13350 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 13360 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 13370 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 13380 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 13390 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 13400 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 13410 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 13420 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 13430 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 13440 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 13450 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 13460 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 13470 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 13480 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 13490 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 13500 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 13510 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 13520 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 13530 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 13540 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 13550 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 13560 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 13570 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 13580 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 13590 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 13600 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 13610 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 13620 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 13630 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 13640 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 13650 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 13660 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 13670 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 13680 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 13690 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 13700 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 13710 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 13720 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 13730 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 13740 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 13750 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 13760 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 13770 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 13780 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 13790 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 13800 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 13810 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 13820 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 13830 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 13840 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 13850 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 13860 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 13870 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 13880 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 13890 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 13900 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 13910 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 13920 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 13930 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 13940 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 13950 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 13960 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 13970 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 13980 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 13990 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 14000 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 14010 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 14020 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 14030 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 14040 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 14050 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 14060 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 14070 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 14080 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 14090 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 14100 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 14110 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 14120 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 14130 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 14140 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 14150 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 14160 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 14170 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 14180 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 14190 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 14200 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 14210 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 14220 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 14230 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 14240 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 14250 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 14260 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 14270 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 14280 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 14290 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 14300 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 14310 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 14320 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 14330 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 14340 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 14350 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 14360 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 14370 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 14380 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 14390 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 14400 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 14410 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 14420 / 55793], loss: 0.712\n",
      "[Epoch: 1, Batch: 14430 / 55793], loss: 0.691\n",
      "[Epoch: 1, Batch: 14440 / 55793], loss: 0.678\n",
      "[Epoch: 1, Batch: 14450 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 14460 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 14470 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 14480 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 14490 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 14500 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 14510 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 14520 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 14530 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 14540 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 14550 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 14560 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 14570 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 14580 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 14590 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 14600 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 14610 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 14620 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 14630 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 14640 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 14650 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 14660 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 14670 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 14680 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 14690 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 14700 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 14710 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 14720 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 14730 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 14740 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 14750 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 14760 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 14770 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 14780 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 14790 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 14800 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 14810 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 14820 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 14830 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 14840 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 14850 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 14860 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 14870 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 14880 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 14890 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 14900 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 14910 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 14920 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 14930 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 14940 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 14950 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 14960 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 14970 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 14980 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 14990 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 15000 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 15010 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 15020 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 15030 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 15040 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 15050 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 15060 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 15070 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 15080 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 15090 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 15100 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 15110 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 15120 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 15130 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 15140 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 15150 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 15160 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 15170 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 15180 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 15190 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 15200 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 15210 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 15220 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 15230 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 15240 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 15250 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 15260 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 15270 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 15280 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 15290 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 15300 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 15310 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 15320 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 15330 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 15340 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 15350 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 15360 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 15370 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 15380 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 15390 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 15400 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 15410 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 15420 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 15430 / 55793], loss: 0.460\n",
      "[Epoch: 1, Batch: 15440 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 15450 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 15460 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 15470 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 15480 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 15490 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 15500 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 15510 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 15520 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 15530 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 15540 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 15550 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 15560 / 55793], loss: 0.663\n",
      "[Epoch: 1, Batch: 15570 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 15580 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 15590 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 15600 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 15610 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 15620 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 15630 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 15640 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 15650 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 15660 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 15670 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 15680 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 15690 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 15700 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 15710 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 15720 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 15730 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 15740 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 15750 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 15760 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 15770 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 15780 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 15790 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 15800 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 15810 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 15820 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 15830 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 15840 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 15850 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 15860 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 15870 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 15880 / 55793], loss: 0.694\n",
      "[Epoch: 1, Batch: 15890 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 15900 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 15910 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 15920 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 15930 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 15940 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 15950 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 15960 / 55793], loss: 0.470\n",
      "[Epoch: 1, Batch: 15970 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 15980 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 15990 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 16000 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 16010 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 16020 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 16030 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 16040 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 16050 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 16060 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 16070 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 16080 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 16090 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 16100 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 16110 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 16120 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 16130 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 16140 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 16150 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 16160 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 16170 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 16180 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 16190 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 16200 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 16210 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 16220 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 16230 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 16240 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 16250 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 16260 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 16270 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 16280 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 16290 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 16300 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 16310 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 16320 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 16330 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 16340 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 16350 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 16360 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 16370 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 16380 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 16390 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 16400 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 16410 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 16420 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 16430 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 16440 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 16450 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 16460 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 16470 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 16480 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 16490 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 16500 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 16510 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 16520 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 16530 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 16540 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 16550 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 16560 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 16570 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 16580 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 16590 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 16600 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 16610 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 16620 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 16630 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 16640 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 16650 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 16660 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 16670 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 16680 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 16690 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 16700 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 16710 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 16720 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 16730 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 16740 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 16750 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 16760 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 16770 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 16780 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 16790 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 16800 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 16810 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 16820 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 16830 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 16840 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 16850 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 16860 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 16870 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 16880 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 16890 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 16900 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 16910 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 16920 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 16930 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 16940 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 16950 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 16960 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 16970 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 16980 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 16990 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 17000 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 17010 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 17020 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 17030 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 17040 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 17050 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 17060 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 17070 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 17080 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch: 17090 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 17100 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 17110 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 17120 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 17130 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 17140 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 17150 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 17160 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 17170 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 17180 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 17190 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 17200 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 17210 / 55793], loss: 0.672\n",
      "[Epoch: 1, Batch: 17220 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 17230 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 17240 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 17250 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 17260 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 17270 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 17280 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 17290 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 17300 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 17310 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 17320 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 17330 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 17340 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 17350 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 17360 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 17370 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 17380 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 17390 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 17400 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 17410 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 17420 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 17430 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 17440 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 17450 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 17460 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 17470 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 17480 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 17490 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 17500 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 17510 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 17520 / 55793], loss: 0.704\n",
      "[Epoch: 1, Batch: 17530 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 17540 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 17550 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 17560 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 17570 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 17580 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 17590 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 17600 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 17610 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 17620 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 17630 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 17640 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 17650 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 17660 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 17670 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 17680 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 17690 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 17700 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 17710 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 17720 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 17730 / 55793], loss: 0.687\n",
      "[Epoch: 1, Batch: 17740 / 55793], loss: 0.461\n",
      "[Epoch: 1, Batch: 17750 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 17760 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 17770 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 17780 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 17790 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 17800 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 17810 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 17820 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 17830 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 17840 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 17850 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 17860 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 17870 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 17880 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 17890 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 17900 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 17910 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 17920 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 17930 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 17940 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 17950 / 55793], loss: 0.664\n",
      "[Epoch: 1, Batch: 17960 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 17970 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 17980 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 17990 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 18000 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 18010 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 18020 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 18030 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 18040 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 18050 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 18060 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 18070 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 18080 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 18090 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 18100 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 18110 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 18120 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 18130 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 18140 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 18150 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 18160 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 18170 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 18180 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 18190 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 18200 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 18210 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 18220 / 55793], loss: 0.700\n",
      "[Epoch: 1, Batch: 18230 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 18240 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 18250 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 18260 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 18270 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 18280 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 18290 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 18300 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 18310 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 18320 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 18330 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 18340 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 18350 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 18360 / 55793], loss: 0.692\n",
      "[Epoch: 1, Batch: 18370 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 18380 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 18390 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 18400 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 18410 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 18420 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 18430 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 18440 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 18450 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 18460 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 18470 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 18480 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 18490 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 18500 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 18510 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 18520 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 18530 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 18540 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 18550 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 18560 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 18570 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 18580 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 18590 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 18600 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 18610 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 18620 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 18630 / 55793], loss: 0.684\n",
      "[Epoch: 1, Batch: 18640 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 18650 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 18660 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 18670 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 18680 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 18690 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 18700 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 18710 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 18720 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 18730 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 18740 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 18750 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 18760 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 18770 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 18780 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 18790 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 18800 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 18810 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 18820 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 18830 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 18840 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 18850 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 18860 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 18870 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 18880 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 18890 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 18900 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 18910 / 55793], loss: 0.680\n",
      "[Epoch: 1, Batch: 18920 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 18930 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 18940 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 18950 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 18960 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 18970 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 18980 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 18990 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 19000 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 19010 / 55793], loss: 0.696\n",
      "[Epoch: 1, Batch: 19020 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 19030 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 19040 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 19050 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 19060 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 19070 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 19080 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 19090 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 19100 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 19110 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 19120 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 19130 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 19140 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 19150 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 19160 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 19170 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 19180 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 19190 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 19200 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 19210 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 19220 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 19230 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 19240 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 19250 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 19260 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 19270 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 19280 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 19290 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 19300 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 19310 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 19320 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 19330 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 19340 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 19350 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 19360 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 19370 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 19380 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 19390 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 19400 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 19410 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 19420 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 19430 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch: 19440 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 19450 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 19460 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 19470 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 19480 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 19490 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 19500 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 19510 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 19520 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 19530 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 19540 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 19550 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 19560 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 19570 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 19580 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 19590 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 19600 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 19610 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 19620 / 55793], loss: 0.759\n",
      "[Epoch: 1, Batch: 19630 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 19640 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 19650 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 19660 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 19670 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 19680 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 19690 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 19700 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 19710 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 19720 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 19730 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 19740 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 19750 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 19760 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 19770 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 19780 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 19790 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 19800 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 19810 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 19820 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 19830 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 19840 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 19850 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 19860 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 19870 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 19880 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 19890 / 55793], loss: 0.470\n",
      "[Epoch: 1, Batch: 19900 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 19910 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 19920 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 19930 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 19940 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 19950 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 19960 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 19970 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 19980 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 19990 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 20000 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 20010 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 20020 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 20030 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 20040 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 20050 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 20060 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 20070 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 20080 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 20090 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 20100 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 20110 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 20120 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 20130 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 20140 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 20150 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 20160 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 20170 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 20180 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 20190 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 20200 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 20210 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 20220 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 20230 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 20240 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 20250 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 20260 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 20270 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 20280 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 20290 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 20300 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 20310 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 20320 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 20330 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 20340 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 20350 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 20360 / 55793], loss: 0.466\n",
      "[Epoch: 1, Batch: 20370 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 20380 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 20390 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 20400 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 20410 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 20420 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 20430 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 20440 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 20450 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 20460 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 20470 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 20480 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 20490 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 20500 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 20510 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 20520 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 20530 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 20540 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 20550 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 20560 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 20570 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 20580 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 20590 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 20600 / 55793], loss: 0.663\n",
      "[Epoch: 1, Batch: 20610 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 20620 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 20630 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 20640 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 20650 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 20660 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 20670 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 20680 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 20690 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 20700 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 20710 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 20720 / 55793], loss: 0.483\n",
      "[Epoch: 1, Batch: 20730 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 20740 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 20750 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 20760 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 20770 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 20780 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 20790 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 20800 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 20810 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 20820 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 20830 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 20840 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 20850 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 20860 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 20870 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 20880 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 20890 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 20900 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 20910 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 20920 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 20930 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 20940 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 20950 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 20960 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 20970 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 20980 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 20990 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 21000 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 21010 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 21020 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 21030 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 21040 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 21050 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 21060 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 21070 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 21080 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 21090 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 21100 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 21110 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 21120 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 21130 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 21140 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 21150 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 21160 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 21170 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 21180 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 21190 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 21200 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 21210 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 21220 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 21230 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 21240 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 21250 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 21260 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 21270 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 21280 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 21290 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 21300 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 21310 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 21320 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 21330 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 21340 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 21350 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 21360 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 21370 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 21380 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 21390 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 21400 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 21410 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 21420 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 21430 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch: 21440 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 21450 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 21460 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 21470 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 21480 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 21490 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 21500 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 21510 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 21520 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 21530 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 21540 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 21550 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 21560 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 21570 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 21580 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 21590 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 21600 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 21610 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 21620 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 21630 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 21640 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 21650 / 55793], loss: 0.669\n",
      "[Epoch: 1, Batch: 21660 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 21670 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 21680 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 21690 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 21700 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 21710 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 21720 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 21730 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 21740 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 21750 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 21760 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 21770 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 21780 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 21790 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 21800 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 21810 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 21820 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 21830 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 21840 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 21850 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 21860 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 21870 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 21880 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 21890 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 21900 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 21910 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 21920 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 21930 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 21940 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 21950 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 21960 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 21970 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 21980 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 21990 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 22000 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 22010 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 22020 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 22030 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 22040 / 55793], loss: 0.470\n",
      "[Epoch: 1, Batch: 22050 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 22060 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 22070 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 22080 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 22090 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 22100 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 22110 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 22120 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 22130 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 22140 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 22150 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 22160 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 22170 / 55793], loss: 0.472\n",
      "[Epoch: 1, Batch: 22180 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 22190 / 55793], loss: 0.444\n",
      "[Epoch: 1, Batch: 22200 / 55793], loss: 0.461\n",
      "[Epoch: 1, Batch: 22210 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 22220 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 22230 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 22240 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 22250 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 22260 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 22270 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 22280 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 22290 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 22300 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 22310 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 22320 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 22330 / 55793], loss: 0.466\n",
      "[Epoch: 1, Batch: 22340 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 22350 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 22360 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 22370 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 22380 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 22390 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 22400 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 22410 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 22420 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 22430 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 22440 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 22450 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 22460 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 22470 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 22480 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 22490 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 22500 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 22510 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 22520 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 22530 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 22540 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 22550 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 22560 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 22570 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 22580 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 22590 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 22600 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 22610 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 22620 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 22630 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 22640 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 22650 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 22660 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 22670 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 22680 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 22690 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 22700 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 22710 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 22720 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 22730 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 22740 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 22750 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 22760 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 22770 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 22780 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 22790 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 22800 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 22810 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 22820 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 22830 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 22840 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 22850 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 22860 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 22870 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 22880 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 22890 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 22900 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 22910 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 22920 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 22930 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 22940 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 22950 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 22960 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 22970 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 22980 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 22990 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 23000 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 23010 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 23020 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 23030 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 23040 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 23050 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 23060 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 23070 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 23080 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 23090 / 55793], loss: 0.676\n",
      "[Epoch: 1, Batch: 23100 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 23110 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 23120 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 23130 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 23140 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 23150 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 23160 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 23170 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 23180 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 23190 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 23200 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 23210 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 23220 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 23230 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 23240 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 23250 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 23260 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 23270 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 23280 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 23290 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 23300 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 23310 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 23320 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 23330 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 23340 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 23350 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 23360 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 23370 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 23380 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 23390 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 23400 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 23410 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 23420 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 23430 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 23440 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 23450 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 23460 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 23470 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 23480 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 23490 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 23500 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 23510 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 23520 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 23530 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 23540 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 23550 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 23560 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 23570 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 23580 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 23590 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 23600 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 23610 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 23620 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 23630 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 23640 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 23650 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 23660 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 23670 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 23680 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 23690 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 23700 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 23710 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 23720 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 23730 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 23740 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 23750 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 23760 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 23770 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 23780 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 23790 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 23800 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 23810 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 23820 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 23830 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 23840 / 55793], loss: 0.677\n",
      "[Epoch: 1, Batch: 23850 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 23860 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 23870 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 23880 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 23890 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 23900 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 23910 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 23920 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 23930 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 23940 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 23950 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 23960 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 23970 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 23980 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 23990 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 24000 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 24010 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 24020 / 55793], loss: 0.698\n",
      "[Epoch: 1, Batch: 24030 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 24040 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 24050 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 24060 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 24070 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 24080 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 24090 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 24100 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 24110 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 24120 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 24130 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 24140 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 24150 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 24160 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 24170 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 24180 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 24190 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 24200 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 24210 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 24220 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 24230 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 24240 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 24250 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 24260 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 24270 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 24280 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 24290 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 24300 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 24310 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 24320 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 24330 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 24340 / 55793], loss: 0.674\n",
      "[Epoch: 1, Batch: 24350 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 24360 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 24370 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 24380 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 24390 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 24400 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 24410 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 24420 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 24430 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 24440 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 24450 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 24460 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 24470 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 24480 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 24490 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 24500 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 24510 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 24520 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 24530 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 24540 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 24550 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 24560 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 24570 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 24580 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 24590 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 24600 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 24610 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 24620 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 24630 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 24640 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 24650 / 55793], loss: 0.483\n",
      "[Epoch: 1, Batch: 24660 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 24670 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 24680 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 24690 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 24700 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 24710 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 24720 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 24730 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 24740 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 24750 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 24760 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 24770 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 24780 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 24790 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 24800 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 24810 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 24820 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 24830 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 24840 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 24850 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 24860 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 24870 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 24880 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 24890 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 24900 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 24910 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 24920 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 24930 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 24940 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 24950 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 24960 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 24970 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 24980 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 24990 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 25000 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 25010 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 25020 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 25030 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 25040 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 25050 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 25060 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 25070 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 25080 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 25090 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 25100 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 25110 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 25120 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 25130 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 25140 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 25150 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 25160 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 25170 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 25180 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 25190 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 25200 / 55793], loss: 0.461\n",
      "[Epoch: 1, Batch: 25210 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 25220 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 25230 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 25240 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 25250 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 25260 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 25270 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 25280 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 25290 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 25300 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 25310 / 55793], loss: 0.470\n",
      "[Epoch: 1, Batch: 25320 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 25330 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 25340 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 25350 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 25360 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 25370 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 25380 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 25390 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 25400 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 25410 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 25420 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 25430 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 25440 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 25450 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 25460 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 25470 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 25480 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 25490 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 25500 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 25510 / 55793], loss: 0.398\n",
      "[Epoch: 1, Batch: 25520 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 25530 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 25540 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 25550 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 25560 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 25570 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 25580 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 25590 / 55793], loss: 0.679\n",
      "[Epoch: 1, Batch: 25600 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 25610 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 25620 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 25630 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 25640 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 25650 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 25660 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 25670 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 25680 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 25690 / 55793], loss: 0.668\n",
      "[Epoch: 1, Batch: 25700 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 25710 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 25720 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 25730 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 25740 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 25750 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 25760 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 25770 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 25780 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 25790 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 25800 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 25810 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 25820 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 25830 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 25840 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 25850 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 25860 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 25870 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 25880 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 25890 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 25900 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 25910 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 25920 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 25930 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 25940 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 25950 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 25960 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 25970 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 25980 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 25990 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 26000 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 26010 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 26020 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 26030 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 26040 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 26050 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 26060 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 26070 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 26080 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 26090 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 26100 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 26110 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 26120 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 26130 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 26140 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 26150 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 26160 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 26170 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 26180 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 26190 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 26200 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 26210 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 26220 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 26230 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 26240 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 26250 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 26260 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 26270 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 26280 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 26290 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 26300 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 26310 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 26320 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 26330 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 26340 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 26350 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 26360 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 26370 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 26380 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 26390 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 26400 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 26410 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 26420 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 26430 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 26440 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 26450 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 26460 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 26470 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 26480 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 26490 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 26500 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 26510 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 26520 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 26530 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 26540 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 26550 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 26560 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 26570 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 26580 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 26590 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 26600 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 26610 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 26620 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 26630 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 26640 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 26650 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 26660 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 26670 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 26680 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 26690 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 26700 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 26710 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 26720 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 26730 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 26740 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 26750 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 26760 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 26770 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 26780 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 26790 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 26800 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 26810 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 26820 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 26830 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 26840 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 26850 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 26860 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 26870 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 26880 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 26890 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 26900 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 26910 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 26920 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 26930 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 26940 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 26950 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 26960 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 26970 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 26980 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 26990 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 27000 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 27010 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 27020 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 27030 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 27040 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 27050 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 27060 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 27070 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 27080 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 27090 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 27100 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 27110 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 27120 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 27130 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 27140 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 27150 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 27160 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 27170 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 27180 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 27190 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 27200 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 27210 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 27220 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 27230 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 27240 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 27250 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 27260 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 27270 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 27280 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 27290 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 27300 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 27310 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 27320 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 27330 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 27340 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 27350 / 55793], loss: 0.461\n",
      "[Epoch: 1, Batch: 27360 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 27370 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 27380 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 27390 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 27400 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 27410 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 27420 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 27430 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 27440 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 27450 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 27460 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 27470 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 27480 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 27490 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 27500 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 27510 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 27520 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 27530 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 27540 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 27550 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 27560 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 27570 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 27580 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 27590 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 27600 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 27610 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 27620 / 55793], loss: 0.709\n",
      "[Epoch: 1, Batch: 27630 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 27640 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 27650 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 27660 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 27670 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 27680 / 55793], loss: 0.446\n",
      "[Epoch: 1, Batch: 27690 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 27700 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 27710 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 27720 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 27730 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 27740 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 27750 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 27760 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 27770 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 27780 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 27790 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 27800 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 27810 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 27820 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 27830 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 27840 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 27850 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 27860 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 27870 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 27880 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 27890 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 27900 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 27910 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 27920 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 27930 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 27940 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 27950 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 27960 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 27970 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 27980 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 27990 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 28000 / 55793], loss: 0.671\n",
      "[Epoch: 1, Batch: 28010 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 28020 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 28030 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 28040 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 28050 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 28060 / 55793], loss: 0.462\n",
      "[Epoch: 1, Batch: 28070 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 28080 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 28090 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 28100 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 28110 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 28120 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 28130 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 28140 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 28150 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 28160 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 28170 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 28180 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 28190 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 28200 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 28210 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 28220 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 28230 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 28240 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 28250 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 28260 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 28270 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 28280 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 28290 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 28300 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 28310 / 55793], loss: 0.661\n",
      "[Epoch: 1, Batch: 28320 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 28330 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 28340 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 28350 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 28360 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 28370 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 28380 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 28390 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 28400 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 28410 / 55793], loss: 0.669\n",
      "[Epoch: 1, Batch: 28420 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 28430 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 28440 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 28450 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 28460 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 28470 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 28480 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 28490 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 28500 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 28510 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 28520 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 28530 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 28540 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 28550 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 28560 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 28570 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 28580 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 28590 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 28600 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 28610 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 28620 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 28630 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 28640 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 28650 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 28660 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 28670 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 28680 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 28690 / 55793], loss: 0.656\n",
      "[Epoch: 1, Batch: 28700 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 28710 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 28720 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 28730 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 28740 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 28750 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 28760 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 28770 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 28780 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 28790 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 28800 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 28810 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 28820 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 28830 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 28840 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 28850 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 28860 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 28870 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 28880 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 28890 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 28900 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 28910 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 28920 / 55793], loss: 0.460\n",
      "[Epoch: 1, Batch: 28930 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 28940 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 28950 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 28960 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 28970 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 28980 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 28990 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 29000 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 29010 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 29020 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 29030 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 29040 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 29050 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 29060 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 29070 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 29080 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 29090 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 29100 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 29110 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 29120 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 29130 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 29140 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 29150 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 29160 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 29170 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 29180 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 29190 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 29200 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 29210 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 29220 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 29230 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 29240 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 29250 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 29260 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 29270 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 29280 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 29290 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 29300 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 29310 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 29320 / 55793], loss: 0.476\n",
      "[Epoch: 1, Batch: 29330 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 29340 / 55793], loss: 0.683\n",
      "[Epoch: 1, Batch: 29350 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 29360 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 29370 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 29380 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 29390 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 29400 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 29410 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 29420 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 29430 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 29440 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 29450 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 29460 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 29470 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 29480 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 29490 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 29500 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 29510 / 55793], loss: 0.678\n",
      "[Epoch: 1, Batch: 29520 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 29530 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 29540 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 29550 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 29560 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 29570 / 55793], loss: 0.687\n",
      "[Epoch: 1, Batch: 29580 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 29590 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 29600 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 29610 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 29620 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 29630 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 29640 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 29650 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 29660 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 29670 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 29680 / 55793], loss: 0.706\n",
      "[Epoch: 1, Batch: 29690 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 29700 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 29710 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 29720 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 29730 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 29740 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 29750 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 29760 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 29770 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 29780 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 29790 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 29800 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 29810 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 29820 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 29830 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 29840 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 29850 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 29860 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 29870 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 29880 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 29890 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 29900 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 29910 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 29920 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 29930 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 29940 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 29950 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 29960 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 29970 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 29980 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 29990 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 30000 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 30010 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 30020 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 30030 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 30040 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 30050 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 30060 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 30070 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 30080 / 55793], loss: 0.697\n",
      "[Epoch: 1, Batch: 30090 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 30100 / 55793], loss: 0.703\n",
      "[Epoch: 1, Batch: 30110 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 30120 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 30130 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 30140 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 30150 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 30160 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 30170 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 30180 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 30190 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 30200 / 55793], loss: 0.476\n",
      "[Epoch: 1, Batch: 30210 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 30220 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 30230 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 30240 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 30250 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 30260 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 30270 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 30280 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 30290 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 30300 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 30310 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 30320 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 30330 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 30340 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 30350 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 30360 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 30370 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 30380 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 30390 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 30400 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 30410 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 30420 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 30430 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 30440 / 55793], loss: 0.685\n",
      "[Epoch: 1, Batch: 30450 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 30460 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 30470 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 30480 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 30490 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 30500 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 30510 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 30520 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 30530 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 30540 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 30550 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 30560 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 30570 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 30580 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 30590 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 30600 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 30610 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 30620 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 30630 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 30640 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 30650 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 30660 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 30670 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 30680 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 30690 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 30700 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 30710 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 30720 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 30730 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 30740 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 30750 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 30760 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 30770 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 30780 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 30790 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 30800 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 30810 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 30820 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 30830 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 30840 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 30850 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 30860 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 30870 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 30880 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 30890 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 30900 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 30910 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 30920 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 30930 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 30940 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 30950 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 30960 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 30970 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 30980 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 30990 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 31000 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 31010 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 31020 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 31030 / 55793], loss: 0.483\n",
      "[Epoch: 1, Batch: 31040 / 55793], loss: 0.453\n",
      "[Epoch: 1, Batch: 31050 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 31060 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 31070 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 31080 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 31090 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 31100 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 31110 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 31120 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 31130 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 31140 / 55793], loss: 0.672\n",
      "[Epoch: 1, Batch: 31150 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 31160 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 31170 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 31180 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 31190 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 31200 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 31210 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 31220 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 31230 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 31240 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 31250 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 31260 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 31270 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 31280 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 31290 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 31300 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 31310 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 31320 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 31330 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 31340 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 31350 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 31360 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 31370 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 31380 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 31390 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 31400 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 31410 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 31420 / 55793], loss: 0.444\n",
      "[Epoch: 1, Batch: 31430 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 31440 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 31450 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 31460 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 31470 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 31480 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 31490 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 31500 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 31510 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 31520 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 31530 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 31540 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 31550 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 31560 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 31570 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 31580 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 31590 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 31600 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 31610 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 31620 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 31630 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 31640 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 31650 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 31660 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 31670 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 31680 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 31690 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 31700 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 31710 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 31720 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 31730 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 31740 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 31750 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 31760 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 31770 / 55793], loss: 0.459\n",
      "[Epoch: 1, Batch: 31780 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 31790 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 31800 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 31810 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 31820 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 31830 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 31840 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 31850 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 31860 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 31870 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 31880 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 31890 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 31900 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 31910 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 31920 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 31930 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 31940 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 31950 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 31960 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 31970 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 31980 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 31990 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 32000 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 32010 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 32020 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 32030 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 32040 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 32050 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 32060 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 32070 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 32080 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 32090 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 32100 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 32110 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 32120 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 32130 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 32140 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 32150 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 32160 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 32170 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 32180 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 32190 / 55793], loss: 0.435\n",
      "[Epoch: 1, Batch: 32200 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 32210 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 32220 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 32230 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 32240 / 55793], loss: 0.658\n",
      "[Epoch: 1, Batch: 32250 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 32260 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 32270 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 32280 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 32290 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 32300 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 32310 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 32320 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 32330 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 32340 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 32350 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 32360 / 55793], loss: 0.664\n",
      "[Epoch: 1, Batch: 32370 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 32380 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 32390 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 32400 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 32410 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 32420 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 32430 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 32440 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 32450 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 32460 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 32470 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 32480 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 32490 / 55793], loss: 0.469\n",
      "[Epoch: 1, Batch: 32500 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 32510 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 32520 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 32530 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 32540 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 32550 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 32560 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 32570 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 32580 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 32590 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 32600 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 32610 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 32620 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 32630 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 32640 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 32650 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 32660 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 32670 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 32680 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 32690 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 32700 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 32710 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 32720 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 32730 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 32740 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 32750 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 32760 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 32770 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 32780 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 32790 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 32800 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 32810 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 32820 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 32830 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 32840 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 32850 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 32860 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 32870 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 32880 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 32890 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 32900 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 32910 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 32920 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 32930 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 32940 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 32950 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 32960 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 32970 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 32980 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 32990 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 33000 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 33010 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 33020 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 33030 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 33040 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 33050 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 33060 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 33070 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 33080 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 33090 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 33100 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 33110 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 33120 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 33130 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 33140 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 33150 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 33160 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 33170 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 33180 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 33190 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 33200 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 33210 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 33220 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 33230 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 33240 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 33250 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 33260 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 33270 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 33280 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 33290 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 33300 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 33310 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 33320 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 33330 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 33340 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 33350 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 33360 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 33370 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 33380 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 33390 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 33400 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 33410 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 33420 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 33430 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 33440 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 33450 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 33460 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 33470 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 33480 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 33490 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 33500 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 33510 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 33520 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 33530 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 33540 / 55793], loss: 0.648\n",
      "[Epoch: 1, Batch: 33550 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 33560 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 33570 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 33580 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 33590 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 33600 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 33610 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 33620 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 33630 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 33640 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 33650 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 33660 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 33670 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 33680 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 33690 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 33700 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 33710 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 33720 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 33730 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 33740 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 33750 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 33760 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 33770 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 33780 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 33790 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 33800 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 33810 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 33820 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 33830 / 55793], loss: 0.449\n",
      "[Epoch: 1, Batch: 33840 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 33850 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 33860 / 55793], loss: 0.424\n",
      "[Epoch: 1, Batch: 33870 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 33880 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 33890 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 33900 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 33910 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 33920 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 33930 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 33940 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 33950 / 55793], loss: 0.417\n",
      "[Epoch: 1, Batch: 33960 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 33970 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 33980 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 33990 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 34000 / 55793], loss: 0.685\n",
      "[Epoch: 1, Batch: 34010 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 34020 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 34030 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 34040 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 34050 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 34060 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 34070 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 34080 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 34090 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 34100 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 34110 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 34120 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 34130 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 34140 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 34150 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 34160 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 34170 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 34180 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 34190 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 34200 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 34210 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 34220 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 34230 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 34240 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 34250 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 34260 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 34270 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 34280 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 34290 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 34300 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 34310 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 34320 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 34330 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 34340 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 34350 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 34360 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 34370 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 34380 / 55793], loss: 0.651\n",
      "[Epoch: 1, Batch: 34390 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 34400 / 55793], loss: 0.476\n",
      "[Epoch: 1, Batch: 34410 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 34420 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 34430 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 34440 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 34450 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 34460 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 34470 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 34480 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 34490 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 34500 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 34510 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 34520 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 34530 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 34540 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 34550 / 55793], loss: 0.653\n",
      "[Epoch: 1, Batch: 34560 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 34570 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 34580 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 34590 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 34600 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 34610 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 34620 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 34630 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 34640 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 34650 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 34660 / 55793], loss: 0.476\n",
      "[Epoch: 1, Batch: 34670 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 34680 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 34690 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 34700 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 34710 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 34720 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 34730 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 34740 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 34750 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 34760 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 34770 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 34780 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 34790 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 34800 / 55793], loss: 0.476\n",
      "[Epoch: 1, Batch: 34810 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 34820 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 34830 / 55793], loss: 0.462\n",
      "[Epoch: 1, Batch: 34840 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 34850 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 34860 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 34870 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 34880 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 34890 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 34900 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 34910 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 34920 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 34930 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 34940 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 34950 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 34960 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 34970 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 34980 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 34990 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 35000 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 35010 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 35020 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 35030 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 35040 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 35050 / 55793], loss: 0.712\n",
      "[Epoch: 1, Batch: 35060 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 35070 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 35080 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 35090 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 35100 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 35110 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 35120 / 55793], loss: 0.462\n",
      "[Epoch: 1, Batch: 35130 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 35140 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 35150 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 35160 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 35170 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 35180 / 55793], loss: 0.438\n",
      "[Epoch: 1, Batch: 35190 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 35200 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 35210 / 55793], loss: 0.450\n",
      "[Epoch: 1, Batch: 35220 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 35230 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 35240 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 35250 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 35260 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 35270 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 35280 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 35290 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 35300 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 35310 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 35320 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 35330 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 35340 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 35350 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 35360 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 35370 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 35380 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 35390 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 35400 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 35410 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 35420 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 35430 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 35440 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 35450 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 35460 / 55793], loss: 0.462\n",
      "[Epoch: 1, Batch: 35470 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 35480 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 35490 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 35500 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 35510 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 35520 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 35530 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 35540 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 35550 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 35560 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 35570 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 35580 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 35590 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 35600 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 35610 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 35620 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 35630 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 35640 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 35650 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 35660 / 55793], loss: 0.401\n",
      "[Epoch: 1, Batch: 35670 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 35680 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 35690 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 35700 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 35710 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 35720 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 35730 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 35740 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 35750 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 35760 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 35770 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 35780 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 35790 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 35800 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 35810 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 35820 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 35830 / 55793], loss: 0.682\n",
      "[Epoch: 1, Batch: 35840 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 35850 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 35860 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 35870 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 35880 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 35890 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 35900 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 35910 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 35920 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 35930 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 35940 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 35950 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 35960 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 35970 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 35980 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 35990 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 36000 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 36010 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 36020 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 36030 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 36040 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 36050 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 36060 / 55793], loss: 0.427\n",
      "[Epoch: 1, Batch: 36070 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 36080 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 36090 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 36100 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 36110 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 36120 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 36130 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 36140 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 36150 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 36160 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 36170 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 36180 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 36190 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 36200 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 36210 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 36220 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 36230 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 36240 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 36250 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 36260 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 36270 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 36280 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 36290 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 36300 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 36310 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 36320 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 36330 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 36340 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 36350 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 36360 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 36370 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 36380 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 36390 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 36400 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 36410 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 36420 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 36430 / 55793], loss: 0.472\n",
      "[Epoch: 1, Batch: 36440 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 36450 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 36460 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 36470 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 36480 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 36490 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 36500 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 36510 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 36520 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 36530 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 36540 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 36550 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 36560 / 55793], loss: 0.431\n",
      "[Epoch: 1, Batch: 36570 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 36580 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 36590 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 36600 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 36610 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 36620 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 36630 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 36640 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 36650 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 36660 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 36670 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 36680 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 36690 / 55793], loss: 0.472\n",
      "[Epoch: 1, Batch: 36700 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 36710 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 36720 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 36730 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 36740 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 36750 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 36760 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 36770 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 36780 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 36790 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 36800 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 36810 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 36820 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 36830 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 36840 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 36850 / 55793], loss: 0.691\n",
      "[Epoch: 1, Batch: 36860 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 36870 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 36880 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 36890 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 36900 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 36910 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 36920 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 36930 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 36940 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 36950 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 36960 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 36970 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 36980 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 36990 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 37000 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 37010 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 37020 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 37030 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 37040 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 37050 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 37060 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 37070 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 37080 / 55793], loss: 0.460\n",
      "[Epoch: 1, Batch: 37090 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 37100 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 37110 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 37120 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 37130 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 37140 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 37150 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 37160 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 37170 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 37180 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 37190 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 37200 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 37210 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 37220 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 37230 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 37240 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 37250 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 37260 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 37270 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 37280 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 37290 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 37300 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 37310 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 37320 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 37330 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 37340 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 37350 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 37360 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 37370 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 37380 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 37390 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 37400 / 55793], loss: 0.469\n",
      "[Epoch: 1, Batch: 37410 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 37420 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 37430 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 37440 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 37450 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 37460 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 37470 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 37480 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 37490 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 37500 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 37510 / 55793], loss: 0.448\n",
      "[Epoch: 1, Batch: 37520 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 37530 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 37540 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 37550 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 37560 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 37570 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 37580 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 37590 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 37600 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 37610 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 37620 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 37630 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 37640 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 37650 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 37660 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 37670 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 37680 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 37690 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 37700 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 37710 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 37720 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 37730 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 37740 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 37750 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 37760 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 37770 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 37780 / 55793], loss: 0.411\n",
      "[Epoch: 1, Batch: 37790 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 37800 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 37810 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 37820 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 37830 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 37840 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 37850 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 37860 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 37870 / 55793], loss: 0.726\n",
      "[Epoch: 1, Batch: 37880 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 37890 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 37900 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 37910 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 37920 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 37930 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 37940 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 37950 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 37960 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 37970 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 37980 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 37990 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 38000 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 38010 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 38020 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 38030 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 38040 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 38050 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 38060 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 38070 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 38080 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 38090 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 38100 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 38110 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 38120 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 38130 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 38140 / 55793], loss: 0.669\n",
      "[Epoch: 1, Batch: 38150 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 38160 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 38170 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 38180 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 38190 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 38200 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 38210 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 38220 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 38230 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 38240 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 38250 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 38260 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 38270 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 38280 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 38290 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 38300 / 55793], loss: 0.641\n",
      "[Epoch: 1, Batch: 38310 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 38320 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 38330 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 38340 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 38350 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 38360 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 38370 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 38380 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 38390 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 38400 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 38410 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 38420 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 38430 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 38440 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 38450 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 38460 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 38470 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 38480 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 38490 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 38500 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 38510 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 38520 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 38530 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 38540 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 38550 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 38560 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 38570 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 38580 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 38590 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 38600 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 38610 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 38620 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 38630 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 38640 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 38650 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 38660 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 38670 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 38680 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 38690 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 38700 / 55793], loss: 0.446\n",
      "[Epoch: 1, Batch: 38710 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 38720 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 38730 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 38740 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 38750 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 38760 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 38770 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 38780 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 38790 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 38800 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 38810 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 38820 / 55793], loss: 0.645\n",
      "[Epoch: 1, Batch: 38830 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 38840 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 38850 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 38860 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 38870 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 38880 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 38890 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 38900 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 38910 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 38920 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 38930 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 38940 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 38950 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 38960 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 38970 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 38980 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 38990 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 39000 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 39010 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 39020 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 39030 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 39040 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 39050 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 39060 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 39070 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 39080 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 39090 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 39100 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 39110 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 39120 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 39130 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 39140 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 39150 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 39160 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 39170 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 39180 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 39190 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 39200 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 39210 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 39220 / 55793], loss: 0.666\n",
      "[Epoch: 1, Batch: 39230 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 39240 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 39250 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 39260 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 39270 / 55793], loss: 0.450\n",
      "[Epoch: 1, Batch: 39280 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 39290 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 39300 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 39310 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 39320 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 39330 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 39340 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 39350 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 39360 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 39370 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 39380 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 39390 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 39400 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 39410 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 39420 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 39430 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 39440 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 39450 / 55793], loss: 0.472\n",
      "[Epoch: 1, Batch: 39460 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 39470 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 39480 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 39490 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 39500 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 39510 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 39520 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 39530 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 39540 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 39550 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 39560 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 39570 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 39580 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 39590 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 39600 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 39610 / 55793], loss: 0.687\n",
      "[Epoch: 1, Batch: 39620 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 39630 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 39640 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 39650 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 39660 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 39670 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 39680 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 39690 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 39700 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 39710 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 39720 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 39730 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 39740 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 39750 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 39760 / 55793], loss: 0.444\n",
      "[Epoch: 1, Batch: 39770 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 39780 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 39790 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 39800 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 39810 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 39820 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 39830 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 39840 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 39850 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 39860 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 39870 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 39880 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 39890 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 39900 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 39910 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 39920 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 39930 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 39940 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 39950 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 39960 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 39970 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 39980 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 39990 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 40000 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 40010 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 40020 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 40030 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 40040 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 40050 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 40060 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 40070 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 40080 / 55793], loss: 0.442\n",
      "[Epoch: 1, Batch: 40090 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 40100 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 40110 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 40120 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 40130 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 40140 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 40150 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 40160 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 40170 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 40180 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 40190 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 40200 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 40210 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 40220 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 40230 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 40240 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 40250 / 55793], loss: 0.437\n",
      "[Epoch: 1, Batch: 40260 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 40270 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 40280 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 40290 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 40300 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 40310 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 40320 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 40330 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 40340 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 40350 / 55793], loss: 0.458\n",
      "[Epoch: 1, Batch: 40360 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 40370 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 40380 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 40390 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 40400 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 40410 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 40420 / 55793], loss: 0.476\n",
      "[Epoch: 1, Batch: 40430 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 40440 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 40450 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 40460 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 40470 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 40480 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 40490 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 40500 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 40510 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 40520 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 40530 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 40540 / 55793], loss: 0.643\n",
      "[Epoch: 1, Batch: 40550 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 40560 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 40570 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 40580 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 40590 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 40600 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 40610 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 40620 / 55793], loss: 0.438\n",
      "[Epoch: 1, Batch: 40630 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 40640 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 40650 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 40660 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 40670 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 40680 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 40690 / 55793], loss: 0.472\n",
      "[Epoch: 1, Batch: 40700 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 40710 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 40720 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 40730 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 40740 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 40750 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 40760 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 40770 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 40780 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 40790 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 40800 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 40810 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 40820 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 40830 / 55793], loss: 0.419\n",
      "[Epoch: 1, Batch: 40840 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 40850 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 40860 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 40870 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 40880 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 40890 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 40900 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 40910 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 40920 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 40930 / 55793], loss: 0.719\n",
      "[Epoch: 1, Batch: 40940 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 40950 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 40960 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 40970 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 40980 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 40990 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 41000 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 41010 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 41020 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 41030 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 41040 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 41050 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 41060 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 41070 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 41080 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 41090 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 41100 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 41110 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 41120 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 41130 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 41140 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 41150 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 41160 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 41170 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 41180 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 41190 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 41200 / 55793], loss: 0.657\n",
      "[Epoch: 1, Batch: 41210 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 41220 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 41230 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 41240 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 41250 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 41260 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 41270 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 41280 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 41290 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 41300 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 41310 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 41320 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 41330 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 41340 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 41350 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 41360 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 41370 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 41380 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 41390 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 41400 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 41410 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 41420 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 41430 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 41440 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 41450 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 41460 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 41470 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 41480 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 41490 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 41500 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 41510 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 41520 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 41530 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 41540 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 41550 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 41560 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 41570 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 41580 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 41590 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 41600 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 41610 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 41620 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 41630 / 55793], loss: 0.411\n",
      "[Epoch: 1, Batch: 41640 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 41650 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 41660 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 41670 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 41680 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 41690 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 41700 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 41710 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 41720 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 41730 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 41740 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 41750 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 41760 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 41770 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 41780 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 41790 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 41800 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 41810 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 41820 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 41830 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 41840 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 41850 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 41860 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 41870 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 41880 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 41890 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 41900 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 41910 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 41920 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 41930 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 41940 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 41950 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 41960 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 41970 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 41980 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 41990 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 42000 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 42010 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 42020 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 42030 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 42040 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 42050 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 42060 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 42070 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 42080 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 42090 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 42100 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 42110 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 42120 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 42130 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 42140 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 42150 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 42160 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 42170 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 42180 / 55793], loss: 0.461\n",
      "[Epoch: 1, Batch: 42190 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 42200 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 42210 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 42220 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 42230 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 42240 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 42250 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 42260 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 42270 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 42280 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 42290 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 42300 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 42310 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 42320 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 42330 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 42340 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 42350 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 42360 / 55793], loss: 0.447\n",
      "[Epoch: 1, Batch: 42370 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 42380 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 42390 / 55793], loss: 0.449\n",
      "[Epoch: 1, Batch: 42400 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 42410 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 42420 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 42430 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 42440 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 42450 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 42460 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 42470 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 42480 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 42490 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 42500 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 42510 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 42520 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 42530 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 42540 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 42550 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 42560 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 42570 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 42580 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 42590 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 42600 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 42610 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 42620 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 42630 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 42640 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 42650 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 42660 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 42670 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 42680 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 42690 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 42700 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 42710 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 42720 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 42730 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 42740 / 55793], loss: 0.462\n",
      "[Epoch: 1, Batch: 42750 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 42760 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 42770 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 42780 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 42790 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 42800 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 42810 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 42820 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 42830 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 42840 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 42850 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 42860 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 42870 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 42880 / 55793], loss: 0.434\n",
      "[Epoch: 1, Batch: 42890 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 42900 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 42910 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 42920 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 42930 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 42940 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 42950 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 42960 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 42970 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 42980 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 42990 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 43000 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 43010 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 43020 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 43030 / 55793], loss: 0.588\n",
      "[Epoch: 1, Batch: 43040 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 43050 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 43060 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 43070 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 43080 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 43090 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 43100 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 43110 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 43120 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 43130 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 43140 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 43150 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 43160 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 43170 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 43180 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 43190 / 55793], loss: 0.469\n",
      "[Epoch: 1, Batch: 43200 / 55793], loss: 0.461\n",
      "[Epoch: 1, Batch: 43210 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 43220 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 43230 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 43240 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 43250 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 43260 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 43270 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 43280 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 43290 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 43300 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 43310 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 43320 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 43330 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 43340 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 43350 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 43360 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 43370 / 55793], loss: 0.424\n",
      "[Epoch: 1, Batch: 43380 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 43390 / 55793], loss: 0.483\n",
      "[Epoch: 1, Batch: 43400 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 43410 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 43420 / 55793], loss: 0.640\n",
      "[Epoch: 1, Batch: 43430 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 43440 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 43450 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 43460 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 43470 / 55793], loss: 0.638\n",
      "[Epoch: 1, Batch: 43480 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 43490 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 43500 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 43510 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 43520 / 55793], loss: 0.455\n",
      "[Epoch: 1, Batch: 43530 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 43540 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 43550 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 43560 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 43570 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 43580 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 43590 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 43600 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 43610 / 55793], loss: 0.650\n",
      "[Epoch: 1, Batch: 43620 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 43630 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 43640 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 43650 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 43660 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 43670 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 43680 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 43690 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 43700 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 43710 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 43720 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 43730 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 43740 / 55793], loss: 0.448\n",
      "[Epoch: 1, Batch: 43750 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 43760 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 43770 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 43780 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 43790 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 43800 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 43810 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 43820 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 43830 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 43840 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 43850 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 43860 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 43870 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 43880 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 43890 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 43900 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 43910 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 43920 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 43930 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 43940 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 43950 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 43960 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 43970 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 43980 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 43990 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 44000 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 44010 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 44020 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 44030 / 55793], loss: 0.462\n",
      "[Epoch: 1, Batch: 44040 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 44050 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 44060 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 44070 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 44080 / 55793], loss: 0.459\n",
      "[Epoch: 1, Batch: 44090 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 44100 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 44110 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 44120 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 44130 / 55793], loss: 0.452\n",
      "[Epoch: 1, Batch: 44140 / 55793], loss: 0.447\n",
      "[Epoch: 1, Batch: 44150 / 55793], loss: 0.450\n",
      "[Epoch: 1, Batch: 44160 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 44170 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 44180 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 44190 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 44200 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 44210 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 44220 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 44230 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 44240 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 44250 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 44260 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 44270 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 44280 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 44290 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 44300 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 44310 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 44320 / 55793], loss: 0.470\n",
      "[Epoch: 1, Batch: 44330 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 44340 / 55793], loss: 0.456\n",
      "[Epoch: 1, Batch: 44350 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 44360 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 44370 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 44380 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 44390 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 44400 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 44410 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 44420 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 44430 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 44440 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 44450 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 44460 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 44470 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 44480 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 44490 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 44500 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 44510 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 44520 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 44530 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 44540 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 44550 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 44560 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 44570 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 44580 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 44590 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 44600 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 44610 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 44620 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 44630 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 44640 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 44650 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 44660 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 44670 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 44680 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 44690 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 44700 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 44710 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 44720 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 44730 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 44740 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 44750 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 44760 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 44770 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 44780 / 55793], loss: 0.602\n",
      "[Epoch: 1, Batch: 44790 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 44800 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 44810 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 44820 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 44830 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 44840 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 44850 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 44860 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 44870 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 44880 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 44890 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 44900 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 44910 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 44920 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 44930 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 44940 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 44950 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 44960 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 44970 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 44980 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 44990 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 45000 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 45010 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 45020 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 45030 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 45040 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 45050 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 45060 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 45070 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 45080 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 45090 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 45100 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 45110 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 45120 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 45130 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 45140 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 45150 / 55793], loss: 0.449\n",
      "[Epoch: 1, Batch: 45160 / 55793], loss: 0.450\n",
      "[Epoch: 1, Batch: 45170 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 45180 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 45190 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 45200 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 45210 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 45220 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 45230 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 45240 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 45250 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 45260 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 45270 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 45280 / 55793], loss: 0.625\n",
      "[Epoch: 1, Batch: 45290 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 45300 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 45310 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 45320 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 45330 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 45340 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 45350 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 45360 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 45370 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 45380 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 45390 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 45400 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 45410 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 45420 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 45430 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 45440 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 45450 / 55793], loss: 0.442\n",
      "[Epoch: 1, Batch: 45460 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 45470 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 45480 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 45490 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 45500 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 45510 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 45520 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 45530 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 45540 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 45550 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 45560 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 45570 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 45580 / 55793], loss: 0.442\n",
      "[Epoch: 1, Batch: 45590 / 55793], loss: 0.722\n",
      "[Epoch: 1, Batch: 45600 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 45610 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 45620 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 45630 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 45640 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 45650 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 45660 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 45670 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 45680 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 45690 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 45700 / 55793], loss: 0.462\n",
      "[Epoch: 1, Batch: 45710 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 45720 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 45730 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 45740 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 45750 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 45760 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 45770 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 45780 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 45790 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 45800 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 45810 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 45820 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 45830 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 45840 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 45850 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 45860 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 45870 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 45880 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 45890 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 45900 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 45910 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 45920 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 45930 / 55793], loss: 0.458\n",
      "[Epoch: 1, Batch: 45940 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 45950 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 45960 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 45970 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 45980 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 45990 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 46000 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 46010 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 46020 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 46030 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 46040 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 46050 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 46060 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 46070 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 46080 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 46090 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 46100 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 46110 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 46120 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 46130 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 46140 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 46150 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 46160 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 46170 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 46180 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 46190 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 46200 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 46210 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 46220 / 55793], loss: 0.421\n",
      "[Epoch: 1, Batch: 46230 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 46240 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 46250 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 46260 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 46270 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 46280 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 46290 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 46300 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 46310 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 46320 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 46330 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 46340 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 46350 / 55793], loss: 0.449\n",
      "[Epoch: 1, Batch: 46360 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 46370 / 55793], loss: 0.608\n",
      "[Epoch: 1, Batch: 46380 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 46390 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 46400 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 46410 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 46420 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 46430 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 46440 / 55793], loss: 0.469\n",
      "[Epoch: 1, Batch: 46450 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 46460 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 46470 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 46480 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 46490 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 46500 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 46510 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 46520 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 46530 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 46540 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 46550 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 46560 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 46570 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 46580 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 46590 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 46600 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 46610 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 46620 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 46630 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 46640 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 46650 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 46660 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 46670 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 46680 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 46690 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 46700 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 46710 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 46720 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 46730 / 55793], loss: 0.635\n",
      "[Epoch: 1, Batch: 46740 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 46750 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 46760 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 46770 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 46780 / 55793], loss: 0.615\n",
      "[Epoch: 1, Batch: 46790 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 46800 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 46810 / 55793], loss: 0.483\n",
      "[Epoch: 1, Batch: 46820 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 46830 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 46840 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 46850 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 46860 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 46870 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 46880 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 46890 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 46900 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 46910 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 46920 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 46930 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 46940 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 46950 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 46960 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 46970 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 46980 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 46990 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 47000 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 47010 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 47020 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 47030 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 47040 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 47050 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 47060 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 47070 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 47080 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 47090 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 47100 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 47110 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 47120 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 47130 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 47140 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 47150 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 47160 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 47170 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 47180 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 47190 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 47200 / 55793], loss: 0.447\n",
      "[Epoch: 1, Batch: 47210 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 47220 / 55793], loss: 0.437\n",
      "[Epoch: 1, Batch: 47230 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 47240 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 47250 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 47260 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 47270 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 47280 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 47290 / 55793], loss: 0.426\n",
      "[Epoch: 1, Batch: 47300 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 47310 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 47320 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 47330 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 47340 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 47350 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 47360 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 47370 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 47380 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 47390 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 47400 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 47410 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 47420 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 47430 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 47440 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 47450 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 47460 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 47470 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 47480 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 47490 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 47500 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 47510 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 47520 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 47530 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 47540 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 47550 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 47560 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 47570 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 47580 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 47590 / 55793], loss: 0.469\n",
      "[Epoch: 1, Batch: 47600 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 47610 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 47620 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 47630 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 47640 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 47650 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 47660 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 47670 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 47680 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 47690 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 47700 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 47710 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 47720 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 47730 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 47740 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 47750 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 47760 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 47770 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 47780 / 55793], loss: 0.582\n",
      "[Epoch: 1, Batch: 47790 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 47800 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 47810 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 47820 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 47830 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 47840 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 47850 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 47860 / 55793], loss: 0.578\n",
      "[Epoch: 1, Batch: 47870 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 47880 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 47890 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 47900 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 47910 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 47920 / 55793], loss: 0.453\n",
      "[Epoch: 1, Batch: 47930 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 47940 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 47950 / 55793], loss: 0.448\n",
      "[Epoch: 1, Batch: 47960 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 47970 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 47980 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 47990 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 48000 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 48010 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 48020 / 55793], loss: 0.681\n",
      "[Epoch: 1, Batch: 48030 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 48040 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 48050 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 48060 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 48070 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 48080 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 48090 / 55793], loss: 0.470\n",
      "[Epoch: 1, Batch: 48100 / 55793], loss: 0.466\n",
      "[Epoch: 1, Batch: 48110 / 55793], loss: 0.606\n",
      "[Epoch: 1, Batch: 48120 / 55793], loss: 0.396\n",
      "[Epoch: 1, Batch: 48130 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 48140 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 48150 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 48160 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 48170 / 55793], loss: 0.459\n",
      "[Epoch: 1, Batch: 48180 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 48190 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 48200 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 48210 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 48220 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 48230 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 48240 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 48250 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 48260 / 55793], loss: 0.452\n",
      "[Epoch: 1, Batch: 48270 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 48280 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 48290 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 48300 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 48310 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 48320 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 48330 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 48340 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 48350 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 48360 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 48370 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 48380 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 48390 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 48400 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 48410 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 48420 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 48430 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 48440 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 48450 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 48460 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 48470 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 48480 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 48490 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 48500 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 48510 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 48520 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 48530 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 48540 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 48550 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 48560 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 48570 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 48580 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 48590 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 48600 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 48610 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 48620 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 48630 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 48640 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 48650 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 48660 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 48670 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 48680 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 48690 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 48700 / 55793], loss: 0.624\n",
      "[Epoch: 1, Batch: 48710 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 48720 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 48730 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 48740 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 48750 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 48760 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 48770 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 48780 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 48790 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 48800 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 48810 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 48820 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 48830 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 48840 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 48850 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 48860 / 55793], loss: 0.466\n",
      "[Epoch: 1, Batch: 48870 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 48880 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 48890 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 48900 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 48910 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 48920 / 55793], loss: 0.655\n",
      "[Epoch: 1, Batch: 48930 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 48940 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 48950 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 48960 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 48970 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 48980 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 48990 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 49000 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 49010 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 49020 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 49030 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 49040 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 49050 / 55793], loss: 0.408\n",
      "[Epoch: 1, Batch: 49060 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 49070 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 49080 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 49090 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 49100 / 55793], loss: 0.470\n",
      "[Epoch: 1, Batch: 49110 / 55793], loss: 0.422\n",
      "[Epoch: 1, Batch: 49120 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 49130 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 49140 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 49150 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 49160 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 49170 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 49180 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 49190 / 55793], loss: 0.633\n",
      "[Epoch: 1, Batch: 49200 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 49210 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 49220 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 49230 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 49240 / 55793], loss: 0.646\n",
      "[Epoch: 1, Batch: 49250 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 49260 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 49270 / 55793], loss: 0.425\n",
      "[Epoch: 1, Batch: 49280 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 49290 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 49300 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 49310 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 49320 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 49330 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 49340 / 55793], loss: 0.644\n",
      "[Epoch: 1, Batch: 49350 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 49360 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 49370 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 49380 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 49390 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 49400 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 49410 / 55793], loss: 0.462\n",
      "[Epoch: 1, Batch: 49420 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 49430 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 49440 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 49450 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 49460 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 49470 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 49480 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 49490 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 49500 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 49510 / 55793], loss: 0.662\n",
      "[Epoch: 1, Batch: 49520 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 49530 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 49540 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 49550 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 49560 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 49570 / 55793], loss: 0.621\n",
      "[Epoch: 1, Batch: 49580 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 49590 / 55793], loss: 0.423\n",
      "[Epoch: 1, Batch: 49600 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 49610 / 55793], loss: 0.421\n",
      "[Epoch: 1, Batch: 49620 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 49630 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 49640 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 49650 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 49660 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 49670 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 49680 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 49690 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 49700 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 49710 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 49720 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 49730 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 49740 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 49750 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 49760 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 49770 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 49780 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 49790 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 49800 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 49810 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 49820 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 49830 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 49840 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 49850 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 49860 / 55793], loss: 0.659\n",
      "[Epoch: 1, Batch: 49870 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 49880 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 49890 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 49900 / 55793], loss: 0.424\n",
      "[Epoch: 1, Batch: 49910 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 49920 / 55793], loss: 0.453\n",
      "[Epoch: 1, Batch: 49930 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 49940 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 49950 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 49960 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 49970 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 49980 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 49990 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 50000 / 55793], loss: 0.491\n",
      "[Epoch: 1, Batch: 50010 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 50020 / 55793], loss: 0.439\n",
      "[Epoch: 1, Batch: 50030 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 50040 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 50050 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 50060 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 50070 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 50080 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 50090 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 50100 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 50110 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 50120 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 50130 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 50140 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 50150 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 50160 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 50170 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 50180 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 50190 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 50200 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 50210 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 50220 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 50230 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 50240 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 50250 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 50260 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 50270 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 50280 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 50290 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 50300 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 50310 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 50320 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 50330 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 50340 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 50350 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 50360 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 50370 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 50380 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 50390 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 50400 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 50410 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 50420 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 50430 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 50440 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 50450 / 55793], loss: 0.622\n",
      "[Epoch: 1, Batch: 50460 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 50470 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 50480 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 50490 / 55793], loss: 0.574\n",
      "[Epoch: 1, Batch: 50500 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 50510 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 50520 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 50530 / 55793], loss: 0.426\n",
      "[Epoch: 1, Batch: 50540 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 50550 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 50560 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 50570 / 55793], loss: 0.636\n",
      "[Epoch: 1, Batch: 50580 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 50590 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 50600 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 50610 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 50620 / 55793], loss: 0.591\n",
      "[Epoch: 1, Batch: 50630 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 50640 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 50650 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 50660 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 50670 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 50680 / 55793], loss: 0.454\n",
      "[Epoch: 1, Batch: 50690 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 50700 / 55793], loss: 0.458\n",
      "[Epoch: 1, Batch: 50710 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 50720 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 50730 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 50740 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 50750 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 50760 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 50770 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 50780 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 50790 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 50800 / 55793], loss: 0.438\n",
      "[Epoch: 1, Batch: 50810 / 55793], loss: 0.440\n",
      "[Epoch: 1, Batch: 50820 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 50830 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 50840 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 50850 / 55793], loss: 0.425\n",
      "[Epoch: 1, Batch: 50860 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 50870 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 50880 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 50890 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 50900 / 55793], loss: 0.612\n",
      "[Epoch: 1, Batch: 50910 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 50920 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 50930 / 55793], loss: 0.450\n",
      "[Epoch: 1, Batch: 50940 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 50950 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 50960 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 50970 / 55793], loss: 0.652\n",
      "[Epoch: 1, Batch: 50980 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 50990 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 51000 / 55793], loss: 0.438\n",
      "[Epoch: 1, Batch: 51010 / 55793], loss: 0.438\n",
      "[Epoch: 1, Batch: 51020 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 51030 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 51040 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 51050 / 55793], loss: 0.518\n",
      "[Epoch: 1, Batch: 51060 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 51070 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 51080 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 51090 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 51100 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 51110 / 55793], loss: 0.454\n",
      "[Epoch: 1, Batch: 51120 / 55793], loss: 0.476\n",
      "[Epoch: 1, Batch: 51130 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 51140 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 51150 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 51160 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 51170 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 51180 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 51190 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 51200 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 51210 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 51220 / 55793], loss: 0.472\n",
      "[Epoch: 1, Batch: 51230 / 55793], loss: 0.565\n",
      "[Epoch: 1, Batch: 51240 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 51250 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 51260 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 51270 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 51280 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 51290 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 51300 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 51310 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 51320 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 51330 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 51340 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 51350 / 55793], loss: 0.448\n",
      "[Epoch: 1, Batch: 51360 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 51370 / 55793], loss: 0.464\n",
      "[Epoch: 1, Batch: 51380 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 51390 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 51400 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 51410 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 51420 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 51430 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 51440 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 51450 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 51460 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 51470 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 51480 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 51490 / 55793], loss: 0.628\n",
      "[Epoch: 1, Batch: 51500 / 55793], loss: 0.490\n",
      "[Epoch: 1, Batch: 51510 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 51520 / 55793], loss: 0.460\n",
      "[Epoch: 1, Batch: 51530 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 51540 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 51550 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 51560 / 55793], loss: 0.476\n",
      "[Epoch: 1, Batch: 51570 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 51580 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 51590 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 51600 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 51610 / 55793], loss: 0.627\n",
      "[Epoch: 1, Batch: 51620 / 55793], loss: 0.601\n",
      "[Epoch: 1, Batch: 51630 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 51640 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 51650 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 51660 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 51670 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 51680 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 51690 / 55793], loss: 0.630\n",
      "[Epoch: 1, Batch: 51700 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 51710 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 51720 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 51730 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 51740 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 51750 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 51760 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 51770 / 55793], loss: 0.437\n",
      "[Epoch: 1, Batch: 51780 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 51790 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 51800 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 51810 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 51820 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 51830 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 51840 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 51850 / 55793], loss: 0.555\n",
      "[Epoch: 1, Batch: 51860 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 51870 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 51880 / 55793], loss: 0.436\n",
      "[Epoch: 1, Batch: 51890 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 51900 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 51910 / 55793], loss: 0.443\n",
      "[Epoch: 1, Batch: 51920 / 55793], loss: 0.631\n",
      "[Epoch: 1, Batch: 51930 / 55793], loss: 0.619\n",
      "[Epoch: 1, Batch: 51940 / 55793], loss: 0.614\n",
      "[Epoch: 1, Batch: 51950 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 51960 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 51970 / 55793], loss: 0.552\n",
      "[Epoch: 1, Batch: 51980 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 51990 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 52000 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 52010 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 52020 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 52030 / 55793], loss: 0.496\n",
      "[Epoch: 1, Batch: 52040 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 52050 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 52060 / 55793], loss: 0.448\n",
      "[Epoch: 1, Batch: 52070 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 52080 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 52090 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 52100 / 55793], loss: 0.519\n",
      "[Epoch: 1, Batch: 52110 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 52120 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 52130 / 55793], loss: 0.654\n",
      "[Epoch: 1, Batch: 52140 / 55793], loss: 0.603\n",
      "[Epoch: 1, Batch: 52150 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 52160 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 52170 / 55793], loss: 0.441\n",
      "[Epoch: 1, Batch: 52180 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 52190 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 52200 / 55793], loss: 0.503\n",
      "[Epoch: 1, Batch: 52210 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 52220 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 52230 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 52240 / 55793], loss: 0.448\n",
      "[Epoch: 1, Batch: 52250 / 55793], loss: 0.469\n",
      "[Epoch: 1, Batch: 52260 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 52270 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 52280 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 52290 / 55793], loss: 0.472\n",
      "[Epoch: 1, Batch: 52300 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 52310 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 52320 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 52330 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 52340 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 52350 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 52360 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 52370 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 52380 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 52390 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 52400 / 55793], loss: 0.686\n",
      "[Epoch: 1, Batch: 52410 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 52420 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 52430 / 55793], loss: 0.570\n",
      "[Epoch: 1, Batch: 52440 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 52450 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 52460 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 52470 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 52480 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 52490 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 52500 / 55793], loss: 0.443\n",
      "[Epoch: 1, Batch: 52510 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 52520 / 55793], loss: 0.560\n",
      "[Epoch: 1, Batch: 52530 / 55793], loss: 0.458\n",
      "[Epoch: 1, Batch: 52540 / 55793], loss: 0.670\n",
      "[Epoch: 1, Batch: 52550 / 55793], loss: 0.577\n",
      "[Epoch: 1, Batch: 52560 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 52570 / 55793], loss: 0.642\n",
      "[Epoch: 1, Batch: 52580 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 52590 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 52600 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 52610 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 52620 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 52630 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 52640 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 52650 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 52660 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 52670 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 52680 / 55793], loss: 0.484\n",
      "[Epoch: 1, Batch: 52690 / 55793], loss: 0.461\n",
      "[Epoch: 1, Batch: 52700 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 52710 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 52720 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 52730 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 52740 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 52750 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 52760 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 52770 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 52780 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 52790 / 55793], loss: 0.485\n",
      "[Epoch: 1, Batch: 52800 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 52810 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 52820 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 52830 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 52840 / 55793], loss: 0.598\n",
      "[Epoch: 1, Batch: 52850 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 52860 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 52870 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 52880 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 52890 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 52900 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 52910 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 52920 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 52930 / 55793], loss: 0.466\n",
      "[Epoch: 1, Batch: 52940 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 52950 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 52960 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 52970 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 52980 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 52990 / 55793], loss: 0.559\n",
      "[Epoch: 1, Batch: 53000 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 53010 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 53020 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 53030 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 53040 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 53050 / 55793], loss: 0.456\n",
      "[Epoch: 1, Batch: 53060 / 55793], loss: 0.466\n",
      "[Epoch: 1, Batch: 53070 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 53080 / 55793], loss: 0.623\n",
      "[Epoch: 1, Batch: 53090 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 53100 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 53110 / 55793], loss: 0.515\n",
      "[Epoch: 1, Batch: 53120 / 55793], loss: 0.442\n",
      "[Epoch: 1, Batch: 53130 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 53140 / 55793], loss: 0.509\n",
      "[Epoch: 1, Batch: 53150 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 53160 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 53170 / 55793], loss: 0.567\n",
      "[Epoch: 1, Batch: 53180 / 55793], loss: 0.497\n",
      "[Epoch: 1, Batch: 53190 / 55793], loss: 0.543\n",
      "[Epoch: 1, Batch: 53200 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 53210 / 55793], loss: 0.617\n",
      "[Epoch: 1, Batch: 53220 / 55793], loss: 0.455\n",
      "[Epoch: 1, Batch: 53230 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 53240 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 53250 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 53260 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 53270 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 53280 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 53290 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 53300 / 55793], loss: 0.451\n",
      "[Epoch: 1, Batch: 53310 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 53320 / 55793], loss: 0.479\n",
      "[Epoch: 1, Batch: 53330 / 55793], loss: 0.613\n",
      "[Epoch: 1, Batch: 53340 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 53350 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 53360 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 53370 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 53380 / 55793], loss: 0.583\n",
      "[Epoch: 1, Batch: 53390 / 55793], loss: 0.618\n",
      "[Epoch: 1, Batch: 53400 / 55793], loss: 0.434\n",
      "[Epoch: 1, Batch: 53410 / 55793], loss: 0.457\n",
      "[Epoch: 1, Batch: 53420 / 55793], loss: 0.700\n",
      "[Epoch: 1, Batch: 53430 / 55793], loss: 0.551\n",
      "[Epoch: 1, Batch: 53440 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 53450 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 53460 / 55793], loss: 0.569\n",
      "[Epoch: 1, Batch: 53470 / 55793], loss: 0.561\n",
      "[Epoch: 1, Batch: 53480 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 53490 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 53500 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 53510 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 53520 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 53530 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 53540 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 53550 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 53560 / 55793], loss: 0.600\n",
      "[Epoch: 1, Batch: 53570 / 55793], loss: 0.667\n",
      "[Epoch: 1, Batch: 53580 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 53590 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 53600 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 53610 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 53620 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 53630 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 53640 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 53650 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 53660 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 53670 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 53680 / 55793], loss: 0.526\n",
      "[Epoch: 1, Batch: 53690 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 53700 / 55793], loss: 0.495\n",
      "[Epoch: 1, Batch: 53710 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 53720 / 55793], loss: 0.572\n",
      "[Epoch: 1, Batch: 53730 / 55793], loss: 0.478\n",
      "[Epoch: 1, Batch: 53740 / 55793], loss: 0.593\n",
      "[Epoch: 1, Batch: 53750 / 55793], loss: 0.609\n",
      "[Epoch: 1, Batch: 53760 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 53770 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 53780 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 53790 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 53800 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 53810 / 55793], loss: 0.550\n",
      "[Epoch: 1, Batch: 53820 / 55793], loss: 0.537\n",
      "[Epoch: 1, Batch: 53830 / 55793], loss: 0.533\n",
      "[Epoch: 1, Batch: 53840 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 53850 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 53860 / 55793], loss: 0.573\n",
      "[Epoch: 1, Batch: 53870 / 55793], loss: 0.585\n",
      "[Epoch: 1, Batch: 53880 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 53890 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 53900 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 53910 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 53920 / 55793], loss: 0.611\n",
      "[Epoch: 1, Batch: 53930 / 55793], loss: 0.562\n",
      "[Epoch: 1, Batch: 53940 / 55793], loss: 0.599\n",
      "[Epoch: 1, Batch: 53950 / 55793], loss: 0.516\n",
      "[Epoch: 1, Batch: 53960 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 53970 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 53980 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 53990 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 54000 / 55793], loss: 0.649\n",
      "[Epoch: 1, Batch: 54010 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 54020 / 55793], loss: 0.480\n",
      "[Epoch: 1, Batch: 54030 / 55793], loss: 0.474\n",
      "[Epoch: 1, Batch: 54040 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 54050 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 54060 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 54070 / 55793], loss: 0.470\n",
      "[Epoch: 1, Batch: 54080 / 55793], loss: 0.564\n",
      "[Epoch: 1, Batch: 54090 / 55793], loss: 0.500\n",
      "[Epoch: 1, Batch: 54100 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 54110 / 55793], loss: 0.523\n",
      "[Epoch: 1, Batch: 54120 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 54130 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 54140 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 54150 / 55793], loss: 0.632\n",
      "[Epoch: 1, Batch: 54160 / 55793], loss: 0.634\n",
      "[Epoch: 1, Batch: 54170 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 54180 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 54190 / 55793], loss: 0.530\n",
      "[Epoch: 1, Batch: 54200 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 54210 / 55793], loss: 0.542\n",
      "[Epoch: 1, Batch: 54220 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 54230 / 55793], loss: 0.595\n",
      "[Epoch: 1, Batch: 54240 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 54250 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 54260 / 55793], loss: 0.592\n",
      "[Epoch: 1, Batch: 54270 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 54280 / 55793], loss: 0.556\n",
      "[Epoch: 1, Batch: 54290 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 54300 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 54310 / 55793], loss: 0.528\n",
      "[Epoch: 1, Batch: 54320 / 55793], loss: 0.527\n",
      "[Epoch: 1, Batch: 54330 / 55793], loss: 0.487\n",
      "[Epoch: 1, Batch: 54340 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 54350 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 54360 / 55793], loss: 0.629\n",
      "[Epoch: 1, Batch: 54370 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 54380 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 54390 / 55793], loss: 0.586\n",
      "[Epoch: 1, Batch: 54400 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 54410 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 54420 / 55793], loss: 0.576\n",
      "[Epoch: 1, Batch: 54430 / 55793], loss: 0.467\n",
      "[Epoch: 1, Batch: 54440 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 54450 / 55793], loss: 0.596\n",
      "[Epoch: 1, Batch: 54460 / 55793], loss: 0.568\n",
      "[Epoch: 1, Batch: 54470 / 55793], loss: 0.453\n",
      "[Epoch: 1, Batch: 54480 / 55793], loss: 0.604\n",
      "[Epoch: 1, Batch: 54490 / 55793], loss: 0.594\n",
      "[Epoch: 1, Batch: 54500 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 54510 / 55793], loss: 0.506\n",
      "[Epoch: 1, Batch: 54520 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 54530 / 55793], loss: 0.454\n",
      "[Epoch: 1, Batch: 54540 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 54550 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 54560 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 54570 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 54580 / 55793], loss: 0.452\n",
      "[Epoch: 1, Batch: 54590 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 54600 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 54610 / 55793], loss: 0.465\n",
      "[Epoch: 1, Batch: 54620 / 55793], loss: 0.510\n",
      "[Epoch: 1, Batch: 54630 / 55793], loss: 0.535\n",
      "[Epoch: 1, Batch: 54640 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 54650 / 55793], loss: 0.499\n",
      "[Epoch: 1, Batch: 54660 / 55793], loss: 0.522\n",
      "[Epoch: 1, Batch: 54670 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 54680 / 55793], loss: 0.637\n",
      "[Epoch: 1, Batch: 54690 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 54700 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 54710 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 54720 / 55793], loss: 0.448\n",
      "[Epoch: 1, Batch: 54730 / 55793], loss: 0.581\n",
      "[Epoch: 1, Batch: 54740 / 55793], loss: 0.502\n",
      "[Epoch: 1, Batch: 54750 / 55793], loss: 0.529\n",
      "[Epoch: 1, Batch: 54760 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 54770 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 54780 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 54790 / 55793], loss: 0.626\n",
      "[Epoch: 1, Batch: 54800 / 55793], loss: 0.566\n",
      "[Epoch: 1, Batch: 54810 / 55793], loss: 0.589\n",
      "[Epoch: 1, Batch: 54820 / 55793], loss: 0.620\n",
      "[Epoch: 1, Batch: 54830 / 55793], loss: 0.545\n",
      "[Epoch: 1, Batch: 54840 / 55793], loss: 0.475\n",
      "[Epoch: 1, Batch: 54850 / 55793], loss: 0.544\n",
      "[Epoch: 1, Batch: 54860 / 55793], loss: 0.468\n",
      "[Epoch: 1, Batch: 54870 / 55793], loss: 0.558\n",
      "[Epoch: 1, Batch: 54880 / 55793], loss: 0.483\n",
      "[Epoch: 1, Batch: 54890 / 55793], loss: 0.532\n",
      "[Epoch: 1, Batch: 54900 / 55793], loss: 0.584\n",
      "[Epoch: 1, Batch: 54910 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 54920 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 54930 / 55793], loss: 0.540\n",
      "[Epoch: 1, Batch: 54940 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 54950 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 54960 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 54970 / 55793], loss: 0.616\n",
      "[Epoch: 1, Batch: 54980 / 55793], loss: 0.571\n",
      "[Epoch: 1, Batch: 54990 / 55793], loss: 0.460\n",
      "[Epoch: 1, Batch: 55000 / 55793], loss: 0.477\n",
      "[Epoch: 1, Batch: 55010 / 55793], loss: 0.508\n",
      "[Epoch: 1, Batch: 55020 / 55793], loss: 0.660\n",
      "[Epoch: 1, Batch: 55030 / 55793], loss: 0.536\n",
      "[Epoch: 1, Batch: 55040 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 55050 / 55793], loss: 0.538\n",
      "[Epoch: 1, Batch: 55060 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 55070 / 55793], loss: 0.498\n",
      "[Epoch: 1, Batch: 55080 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 55090 / 55793], loss: 0.461\n",
      "[Epoch: 1, Batch: 55100 / 55793], loss: 0.525\n",
      "[Epoch: 1, Batch: 55110 / 55793], loss: 0.501\n",
      "[Epoch: 1, Batch: 55120 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 55130 / 55793], loss: 0.546\n",
      "[Epoch: 1, Batch: 55140 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 55150 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 55160 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 55170 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 55180 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 55190 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 55200 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 55210 / 55793], loss: 0.512\n",
      "[Epoch: 1, Batch: 55220 / 55793], loss: 0.539\n",
      "[Epoch: 1, Batch: 55230 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 55240 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 55250 / 55793], loss: 0.575\n",
      "[Epoch: 1, Batch: 55260 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 55270 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 55280 / 55793], loss: 0.481\n",
      "[Epoch: 1, Batch: 55290 / 55793], loss: 0.513\n",
      "[Epoch: 1, Batch: 55300 / 55793], loss: 0.432\n",
      "[Epoch: 1, Batch: 55310 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 55320 / 55793], loss: 0.482\n",
      "[Epoch: 1, Batch: 55330 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 55340 / 55793], loss: 0.610\n",
      "[Epoch: 1, Batch: 55350 / 55793], loss: 0.719\n",
      "[Epoch: 1, Batch: 55360 / 55793], loss: 0.486\n",
      "[Epoch: 1, Batch: 55370 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 55380 / 55793], loss: 0.607\n",
      "[Epoch: 1, Batch: 55390 / 55793], loss: 0.524\n",
      "[Epoch: 1, Batch: 55400 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 55410 / 55793], loss: 0.554\n",
      "[Epoch: 1, Batch: 55420 / 55793], loss: 0.507\n",
      "[Epoch: 1, Batch: 55430 / 55793], loss: 0.553\n",
      "[Epoch: 1, Batch: 55440 / 55793], loss: 0.488\n",
      "[Epoch: 1, Batch: 55450 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 55460 / 55793], loss: 0.587\n",
      "[Epoch: 1, Batch: 55470 / 55793], loss: 0.647\n",
      "[Epoch: 1, Batch: 55480 / 55793], loss: 0.534\n",
      "[Epoch: 1, Batch: 55490 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 55500 / 55793], loss: 0.483\n",
      "[Epoch: 1, Batch: 55510 / 55793], loss: 0.505\n",
      "[Epoch: 1, Batch: 55520 / 55793], loss: 0.463\n",
      "[Epoch: 1, Batch: 55530 / 55793], loss: 0.541\n",
      "[Epoch: 1, Batch: 55540 / 55793], loss: 0.521\n",
      "[Epoch: 1, Batch: 55550 / 55793], loss: 0.471\n",
      "[Epoch: 1, Batch: 55560 / 55793], loss: 0.548\n",
      "[Epoch: 1, Batch: 55570 / 55793], loss: 0.563\n",
      "[Epoch: 1, Batch: 55580 / 55793], loss: 0.517\n",
      "[Epoch: 1, Batch: 55590 / 55793], loss: 0.531\n",
      "[Epoch: 1, Batch: 55600 / 55793], loss: 0.547\n",
      "[Epoch: 1, Batch: 55610 / 55793], loss: 0.514\n",
      "[Epoch: 1, Batch: 55620 / 55793], loss: 0.549\n",
      "[Epoch: 1, Batch: 55630 / 55793], loss: 0.489\n",
      "[Epoch: 1, Batch: 55640 / 55793], loss: 0.688\n",
      "[Epoch: 1, Batch: 55650 / 55793], loss: 0.605\n",
      "[Epoch: 1, Batch: 55660 / 55793], loss: 0.494\n",
      "[Epoch: 1, Batch: 55670 / 55793], loss: 0.493\n",
      "[Epoch: 1, Batch: 55680 / 55793], loss: 0.597\n",
      "[Epoch: 1, Batch: 55690 / 55793], loss: 0.557\n",
      "[Epoch: 1, Batch: 55700 / 55793], loss: 0.492\n",
      "[Epoch: 1, Batch: 55710 / 55793], loss: 0.639\n",
      "[Epoch: 1, Batch: 55720 / 55793], loss: 0.473\n",
      "[Epoch: 1, Batch: 55730 / 55793], loss: 0.579\n",
      "[Epoch: 1, Batch: 55740 / 55793], loss: 0.504\n",
      "[Epoch: 1, Batch: 55750 / 55793], loss: 0.520\n",
      "[Epoch: 1, Batch: 55760 / 55793], loss: 0.511\n",
      "[Epoch: 1, Batch: 55770 / 55793], loss: 0.580\n",
      "[Epoch: 1, Batch: 55780 / 55793], loss: 0.590\n",
      "[Epoch: 1, Batch: 55790 / 55793], loss: 0.548\n",
      "Valid accuracy: 84 %\n",
      "Saving model\n"
     ]
    }
   ],
   "source": [
    "train(pointnet, criterion, train_loader, device, val_loader, 3, True, model_weights_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering model weights that were saved for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['save_epoch_0.pth']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights = os.listdir(model_weights_dir)\n",
    "model_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the last epoch model weights for PointNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11144\\2966757700.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('../model_weights/save_epoch_0.pth'))\n"
     ]
    }
   ],
   "source": [
    "# Recreate the model architecture\n",
    "model = PointNet(classes=2)  # Ensure the class arguments are the same as during training\n",
    "\n",
    "# Load the saved state_dict into the model\n",
    "model.load_state_dict(torch.load(os.path.join(model_weights_dir, model_weights[-1]))) # Last epoch model weights\n",
    "\n",
    "# Move the model to the appropriate device and set it to evaluation mode\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating trained PointNet on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch [  10 / 15204]\n",
      "Batch [  20 / 15204]\n",
      "Batch [  30 / 15204]\n",
      "Batch [  40 / 15204]\n",
      "Batch [  50 / 15204]\n",
      "Batch [  60 / 15204]\n",
      "Batch [  70 / 15204]\n",
      "Batch [  80 / 15204]\n",
      "Batch [  90 / 15204]\n",
      "Batch [ 100 / 15204]\n",
      "Batch [ 110 / 15204]\n",
      "Batch [ 120 / 15204]\n",
      "Batch [ 130 / 15204]\n",
      "Batch [ 140 / 15204]\n",
      "Batch [ 150 / 15204]\n",
      "Batch [ 160 / 15204]\n",
      "Batch [ 170 / 15204]\n",
      "Batch [ 180 / 15204]\n",
      "Batch [ 190 / 15204]\n",
      "Batch [ 200 / 15204]\n",
      "Batch [ 210 / 15204]\n",
      "Batch [ 220 / 15204]\n",
      "Batch [ 230 / 15204]\n",
      "Batch [ 240 / 15204]\n",
      "Batch [ 250 / 15204]\n",
      "Batch [ 260 / 15204]\n",
      "Batch [ 270 / 15204]\n",
      "Batch [ 280 / 15204]\n",
      "Batch [ 290 / 15204]\n",
      "Batch [ 300 / 15204]\n",
      "Batch [ 310 / 15204]\n",
      "Batch [ 320 / 15204]\n",
      "Batch [ 330 / 15204]\n",
      "Batch [ 340 / 15204]\n",
      "Batch [ 350 / 15204]\n",
      "Batch [ 360 / 15204]\n",
      "Batch [ 370 / 15204]\n",
      "Batch [ 380 / 15204]\n",
      "Batch [ 390 / 15204]\n",
      "Batch [ 400 / 15204]\n",
      "Batch [ 410 / 15204]\n",
      "Batch [ 420 / 15204]\n",
      "Batch [ 430 / 15204]\n",
      "Batch [ 440 / 15204]\n",
      "Batch [ 450 / 15204]\n",
      "Batch [ 460 / 15204]\n",
      "Batch [ 470 / 15204]\n",
      "Batch [ 480 / 15204]\n",
      "Batch [ 490 / 15204]\n",
      "Batch [ 500 / 15204]\n",
      "Batch [ 510 / 15204]\n",
      "Batch [ 520 / 15204]\n",
      "Batch [ 530 / 15204]\n",
      "Batch [ 540 / 15204]\n",
      "Batch [ 550 / 15204]\n",
      "Batch [ 560 / 15204]\n",
      "Batch [ 570 / 15204]\n",
      "Batch [ 580 / 15204]\n",
      "Batch [ 590 / 15204]\n",
      "Batch [ 600 / 15204]\n",
      "Batch [ 610 / 15204]\n",
      "Batch [ 620 / 15204]\n",
      "Batch [ 630 / 15204]\n",
      "Batch [ 640 / 15204]\n",
      "Batch [ 650 / 15204]\n",
      "Batch [ 660 / 15204]\n",
      "Batch [ 670 / 15204]\n",
      "Batch [ 680 / 15204]\n",
      "Batch [ 690 / 15204]\n",
      "Batch [ 700 / 15204]\n",
      "Batch [ 710 / 15204]\n",
      "Batch [ 720 / 15204]\n",
      "Batch [ 730 / 15204]\n",
      "Batch [ 740 / 15204]\n",
      "Batch [ 750 / 15204]\n",
      "Batch [ 760 / 15204]\n",
      "Batch [ 770 / 15204]\n",
      "Batch [ 780 / 15204]\n",
      "Batch [ 790 / 15204]\n",
      "Batch [ 800 / 15204]\n",
      "Batch [ 810 / 15204]\n",
      "Batch [ 820 / 15204]\n",
      "Batch [ 830 / 15204]\n",
      "Batch [ 840 / 15204]\n",
      "Batch [ 850 / 15204]\n",
      "Batch [ 860 / 15204]\n",
      "Batch [ 870 / 15204]\n",
      "Batch [ 880 / 15204]\n",
      "Batch [ 890 / 15204]\n",
      "Batch [ 900 / 15204]\n",
      "Batch [ 910 / 15204]\n",
      "Batch [ 920 / 15204]\n",
      "Batch [ 930 / 15204]\n",
      "Batch [ 940 / 15204]\n",
      "Batch [ 950 / 15204]\n",
      "Batch [ 960 / 15204]\n",
      "Batch [ 970 / 15204]\n",
      "Batch [ 980 / 15204]\n",
      "Batch [ 990 / 15204]\n",
      "Batch [1000 / 15204]\n",
      "Batch [1010 / 15204]\n",
      "Batch [1020 / 15204]\n",
      "Batch [1030 / 15204]\n",
      "Batch [1040 / 15204]\n",
      "Batch [1050 / 15204]\n",
      "Batch [1060 / 15204]\n",
      "Batch [1070 / 15204]\n",
      "Batch [1080 / 15204]\n",
      "Batch [1090 / 15204]\n",
      "Batch [1100 / 15204]\n",
      "Batch [1110 / 15204]\n",
      "Batch [1120 / 15204]\n",
      "Batch [1130 / 15204]\n",
      "Batch [1140 / 15204]\n",
      "Batch [1150 / 15204]\n",
      "Batch [1160 / 15204]\n",
      "Batch [1170 / 15204]\n",
      "Batch [1180 / 15204]\n",
      "Batch [1190 / 15204]\n",
      "Batch [1200 / 15204]\n",
      "Batch [1210 / 15204]\n",
      "Batch [1220 / 15204]\n",
      "Batch [1230 / 15204]\n",
      "Batch [1240 / 15204]\n",
      "Batch [1250 / 15204]\n",
      "Batch [1260 / 15204]\n",
      "Batch [1270 / 15204]\n",
      "Batch [1280 / 15204]\n",
      "Batch [1290 / 15204]\n",
      "Batch [1300 / 15204]\n",
      "Batch [1310 / 15204]\n",
      "Batch [1320 / 15204]\n",
      "Batch [1330 / 15204]\n",
      "Batch [1340 / 15204]\n",
      "Batch [1350 / 15204]\n",
      "Batch [1360 / 15204]\n",
      "Batch [1370 / 15204]\n",
      "Batch [1380 / 15204]\n",
      "Batch [1390 / 15204]\n",
      "Batch [1400 / 15204]\n",
      "Batch [1410 / 15204]\n",
      "Batch [1420 / 15204]\n",
      "Batch [1430 / 15204]\n",
      "Batch [1440 / 15204]\n",
      "Batch [1450 / 15204]\n",
      "Batch [1460 / 15204]\n",
      "Batch [1470 / 15204]\n",
      "Batch [1480 / 15204]\n",
      "Batch [1490 / 15204]\n",
      "Batch [1500 / 15204]\n",
      "Batch [1510 / 15204]\n",
      "Batch [1520 / 15204]\n",
      "Batch [1530 / 15204]\n",
      "Batch [1540 / 15204]\n",
      "Batch [1550 / 15204]\n",
      "Batch [1560 / 15204]\n",
      "Batch [1570 / 15204]\n",
      "Batch [1580 / 15204]\n",
      "Batch [1590 / 15204]\n",
      "Batch [1600 / 15204]\n",
      "Batch [1610 / 15204]\n",
      "Batch [1620 / 15204]\n",
      "Batch [1630 / 15204]\n",
      "Batch [1640 / 15204]\n",
      "Batch [1650 / 15204]\n",
      "Batch [1660 / 15204]\n",
      "Batch [1670 / 15204]\n",
      "Batch [1680 / 15204]\n",
      "Batch [1690 / 15204]\n",
      "Batch [1700 / 15204]\n",
      "Batch [1710 / 15204]\n",
      "Batch [1720 / 15204]\n",
      "Batch [1730 / 15204]\n",
      "Batch [1740 / 15204]\n",
      "Batch [1750 / 15204]\n",
      "Batch [1760 / 15204]\n",
      "Batch [1770 / 15204]\n",
      "Batch [1780 / 15204]\n",
      "Batch [1790 / 15204]\n",
      "Batch [1800 / 15204]\n",
      "Batch [1810 / 15204]\n",
      "Batch [1820 / 15204]\n",
      "Batch [1830 / 15204]\n",
      "Batch [1840 / 15204]\n",
      "Batch [1850 / 15204]\n",
      "Batch [1860 / 15204]\n",
      "Batch [1870 / 15204]\n",
      "Batch [1880 / 15204]\n",
      "Batch [1890 / 15204]\n",
      "Batch [1900 / 15204]\n",
      "Batch [1910 / 15204]\n",
      "Batch [1920 / 15204]\n",
      "Batch [1930 / 15204]\n",
      "Batch [1940 / 15204]\n",
      "Batch [1950 / 15204]\n",
      "Batch [1960 / 15204]\n",
      "Batch [1970 / 15204]\n",
      "Batch [1980 / 15204]\n",
      "Batch [1990 / 15204]\n",
      "Batch [2000 / 15204]\n",
      "Batch [2010 / 15204]\n",
      "Batch [2020 / 15204]\n",
      "Batch [2030 / 15204]\n",
      "Batch [2040 / 15204]\n",
      "Batch [2050 / 15204]\n",
      "Batch [2060 / 15204]\n",
      "Batch [2070 / 15204]\n",
      "Batch [2080 / 15204]\n",
      "Batch [2090 / 15204]\n",
      "Batch [2100 / 15204]\n",
      "Batch [2110 / 15204]\n",
      "Batch [2120 / 15204]\n",
      "Batch [2130 / 15204]\n",
      "Batch [2140 / 15204]\n",
      "Batch [2150 / 15204]\n",
      "Batch [2160 / 15204]\n",
      "Batch [2170 / 15204]\n",
      "Batch [2180 / 15204]\n",
      "Batch [2190 / 15204]\n",
      "Batch [2200 / 15204]\n",
      "Batch [2210 / 15204]\n",
      "Batch [2220 / 15204]\n",
      "Batch [2230 / 15204]\n",
      "Batch [2240 / 15204]\n",
      "Batch [2250 / 15204]\n",
      "Batch [2260 / 15204]\n",
      "Batch [2270 / 15204]\n",
      "Batch [2280 / 15204]\n",
      "Batch [2290 / 15204]\n",
      "Batch [2300 / 15204]\n",
      "Batch [2310 / 15204]\n",
      "Batch [2320 / 15204]\n",
      "Batch [2330 / 15204]\n",
      "Batch [2340 / 15204]\n",
      "Batch [2350 / 15204]\n",
      "Batch [2360 / 15204]\n",
      "Batch [2370 / 15204]\n",
      "Batch [2380 / 15204]\n",
      "Batch [2390 / 15204]\n",
      "Batch [2400 / 15204]\n",
      "Batch [2410 / 15204]\n",
      "Batch [2420 / 15204]\n",
      "Batch [2430 / 15204]\n",
      "Batch [2440 / 15204]\n",
      "Batch [2450 / 15204]\n",
      "Batch [2460 / 15204]\n",
      "Batch [2470 / 15204]\n",
      "Batch [2480 / 15204]\n",
      "Batch [2490 / 15204]\n",
      "Batch [2500 / 15204]\n",
      "Batch [2510 / 15204]\n",
      "Batch [2520 / 15204]\n",
      "Batch [2530 / 15204]\n",
      "Batch [2540 / 15204]\n",
      "Batch [2550 / 15204]\n",
      "Batch [2560 / 15204]\n",
      "Batch [2570 / 15204]\n",
      "Batch [2580 / 15204]\n",
      "Batch [2590 / 15204]\n",
      "Batch [2600 / 15204]\n",
      "Batch [2610 / 15204]\n",
      "Batch [2620 / 15204]\n",
      "Batch [2630 / 15204]\n",
      "Batch [2640 / 15204]\n",
      "Batch [2650 / 15204]\n",
      "Batch [2660 / 15204]\n",
      "Batch [2670 / 15204]\n",
      "Batch [2680 / 15204]\n",
      "Batch [2690 / 15204]\n",
      "Batch [2700 / 15204]\n",
      "Batch [2710 / 15204]\n",
      "Batch [2720 / 15204]\n",
      "Batch [2730 / 15204]\n",
      "Batch [2740 / 15204]\n",
      "Batch [2750 / 15204]\n",
      "Batch [2760 / 15204]\n",
      "Batch [2770 / 15204]\n",
      "Batch [2780 / 15204]\n",
      "Batch [2790 / 15204]\n",
      "Batch [2800 / 15204]\n",
      "Batch [2810 / 15204]\n",
      "Batch [2820 / 15204]\n",
      "Batch [2830 / 15204]\n",
      "Batch [2840 / 15204]\n",
      "Batch [2850 / 15204]\n",
      "Batch [2860 / 15204]\n",
      "Batch [2870 / 15204]\n",
      "Batch [2880 / 15204]\n",
      "Batch [2890 / 15204]\n",
      "Batch [2900 / 15204]\n",
      "Batch [2910 / 15204]\n",
      "Batch [2920 / 15204]\n",
      "Batch [2930 / 15204]\n",
      "Batch [2940 / 15204]\n",
      "Batch [2950 / 15204]\n",
      "Batch [2960 / 15204]\n",
      "Batch [2970 / 15204]\n",
      "Batch [2980 / 15204]\n",
      "Batch [2990 / 15204]\n",
      "Batch [3000 / 15204]\n",
      "Batch [3010 / 15204]\n",
      "Batch [3020 / 15204]\n",
      "Batch [3030 / 15204]\n",
      "Batch [3040 / 15204]\n",
      "Batch [3050 / 15204]\n",
      "Batch [3060 / 15204]\n",
      "Batch [3070 / 15204]\n",
      "Batch [3080 / 15204]\n",
      "Batch [3090 / 15204]\n",
      "Batch [3100 / 15204]\n",
      "Batch [3110 / 15204]\n",
      "Batch [3120 / 15204]\n",
      "Batch [3130 / 15204]\n",
      "Batch [3140 / 15204]\n",
      "Batch [3150 / 15204]\n",
      "Batch [3160 / 15204]\n",
      "Batch [3170 / 15204]\n",
      "Batch [3180 / 15204]\n",
      "Batch [3190 / 15204]\n",
      "Batch [3200 / 15204]\n",
      "Batch [3210 / 15204]\n",
      "Batch [3220 / 15204]\n",
      "Batch [3230 / 15204]\n",
      "Batch [3240 / 15204]\n",
      "Batch [3250 / 15204]\n",
      "Batch [3260 / 15204]\n",
      "Batch [3270 / 15204]\n",
      "Batch [3280 / 15204]\n",
      "Batch [3290 / 15204]\n",
      "Batch [3300 / 15204]\n",
      "Batch [3310 / 15204]\n",
      "Batch [3320 / 15204]\n",
      "Batch [3330 / 15204]\n",
      "Batch [3340 / 15204]\n",
      "Batch [3350 / 15204]\n",
      "Batch [3360 / 15204]\n",
      "Batch [3370 / 15204]\n",
      "Batch [3380 / 15204]\n",
      "Batch [3390 / 15204]\n",
      "Batch [3400 / 15204]\n",
      "Batch [3410 / 15204]\n",
      "Batch [3420 / 15204]\n",
      "Batch [3430 / 15204]\n",
      "Batch [3440 / 15204]\n",
      "Batch [3450 / 15204]\n",
      "Batch [3460 / 15204]\n",
      "Batch [3470 / 15204]\n",
      "Batch [3480 / 15204]\n",
      "Batch [3490 / 15204]\n",
      "Batch [3500 / 15204]\n",
      "Batch [3510 / 15204]\n",
      "Batch [3520 / 15204]\n",
      "Batch [3530 / 15204]\n",
      "Batch [3540 / 15204]\n",
      "Batch [3550 / 15204]\n",
      "Batch [3560 / 15204]\n",
      "Batch [3570 / 15204]\n",
      "Batch [3580 / 15204]\n",
      "Batch [3590 / 15204]\n",
      "Batch [3600 / 15204]\n",
      "Batch [3610 / 15204]\n",
      "Batch [3620 / 15204]\n",
      "Batch [3630 / 15204]\n",
      "Batch [3640 / 15204]\n",
      "Batch [3650 / 15204]\n",
      "Batch [3660 / 15204]\n",
      "Batch [3670 / 15204]\n",
      "Batch [3680 / 15204]\n",
      "Batch [3690 / 15204]\n",
      "Batch [3700 / 15204]\n",
      "Batch [3710 / 15204]\n",
      "Batch [3720 / 15204]\n",
      "Batch [3730 / 15204]\n",
      "Batch [3740 / 15204]\n",
      "Batch [3750 / 15204]\n",
      "Batch [3760 / 15204]\n",
      "Batch [3770 / 15204]\n",
      "Batch [3780 / 15204]\n",
      "Batch [3790 / 15204]\n",
      "Batch [3800 / 15204]\n",
      "Batch [3810 / 15204]\n",
      "Batch [3820 / 15204]\n",
      "Batch [3830 / 15204]\n",
      "Batch [3840 / 15204]\n",
      "Batch [3850 / 15204]\n",
      "Batch [3860 / 15204]\n",
      "Batch [3870 / 15204]\n",
      "Batch [3880 / 15204]\n",
      "Batch [3890 / 15204]\n",
      "Batch [3900 / 15204]\n",
      "Batch [3910 / 15204]\n",
      "Batch [3920 / 15204]\n",
      "Batch [3930 / 15204]\n",
      "Batch [3940 / 15204]\n",
      "Batch [3950 / 15204]\n",
      "Batch [3960 / 15204]\n",
      "Batch [3970 / 15204]\n",
      "Batch [3980 / 15204]\n",
      "Batch [3990 / 15204]\n",
      "Batch [4000 / 15204]\n",
      "Batch [4010 / 15204]\n",
      "Batch [4020 / 15204]\n",
      "Batch [4030 / 15204]\n",
      "Batch [4040 / 15204]\n",
      "Batch [4050 / 15204]\n",
      "Batch [4060 / 15204]\n",
      "Batch [4070 / 15204]\n",
      "Batch [4080 / 15204]\n",
      "Batch [4090 / 15204]\n",
      "Batch [4100 / 15204]\n",
      "Batch [4110 / 15204]\n",
      "Batch [4120 / 15204]\n",
      "Batch [4130 / 15204]\n",
      "Batch [4140 / 15204]\n",
      "Batch [4150 / 15204]\n",
      "Batch [4160 / 15204]\n",
      "Batch [4170 / 15204]\n",
      "Batch [4180 / 15204]\n",
      "Batch [4190 / 15204]\n",
      "Batch [4200 / 15204]\n",
      "Batch [4210 / 15204]\n",
      "Batch [4220 / 15204]\n",
      "Batch [4230 / 15204]\n",
      "Batch [4240 / 15204]\n",
      "Batch [4250 / 15204]\n",
      "Batch [4260 / 15204]\n",
      "Batch [4270 / 15204]\n",
      "Batch [4280 / 15204]\n",
      "Batch [4290 / 15204]\n",
      "Batch [4300 / 15204]\n",
      "Batch [4310 / 15204]\n",
      "Batch [4320 / 15204]\n",
      "Batch [4330 / 15204]\n",
      "Batch [4340 / 15204]\n",
      "Batch [4350 / 15204]\n",
      "Batch [4360 / 15204]\n",
      "Batch [4370 / 15204]\n",
      "Batch [4380 / 15204]\n",
      "Batch [4390 / 15204]\n",
      "Batch [4400 / 15204]\n",
      "Batch [4410 / 15204]\n",
      "Batch [4420 / 15204]\n",
      "Batch [4430 / 15204]\n",
      "Batch [4440 / 15204]\n",
      "Batch [4450 / 15204]\n",
      "Batch [4460 / 15204]\n",
      "Batch [4470 / 15204]\n",
      "Batch [4480 / 15204]\n",
      "Batch [4490 / 15204]\n",
      "Batch [4500 / 15204]\n",
      "Batch [4510 / 15204]\n",
      "Batch [4520 / 15204]\n",
      "Batch [4530 / 15204]\n",
      "Batch [4540 / 15204]\n",
      "Batch [4550 / 15204]\n",
      "Batch [4560 / 15204]\n",
      "Batch [4570 / 15204]\n",
      "Batch [4580 / 15204]\n",
      "Batch [4590 / 15204]\n",
      "Batch [4600 / 15204]\n",
      "Batch [4610 / 15204]\n",
      "Batch [4620 / 15204]\n",
      "Batch [4630 / 15204]\n",
      "Batch [4640 / 15204]\n",
      "Batch [4650 / 15204]\n",
      "Batch [4660 / 15204]\n",
      "Batch [4670 / 15204]\n",
      "Batch [4680 / 15204]\n",
      "Batch [4690 / 15204]\n",
      "Batch [4700 / 15204]\n",
      "Batch [4710 / 15204]\n",
      "Batch [4720 / 15204]\n",
      "Batch [4730 / 15204]\n",
      "Batch [4740 / 15204]\n",
      "Batch [4750 / 15204]\n",
      "Batch [4760 / 15204]\n",
      "Batch [4770 / 15204]\n",
      "Batch [4780 / 15204]\n",
      "Batch [4790 / 15204]\n",
      "Batch [4800 / 15204]\n",
      "Batch [4810 / 15204]\n",
      "Batch [4820 / 15204]\n",
      "Batch [4830 / 15204]\n",
      "Batch [4840 / 15204]\n",
      "Batch [4850 / 15204]\n",
      "Batch [4860 / 15204]\n",
      "Batch [4870 / 15204]\n",
      "Batch [4880 / 15204]\n",
      "Batch [4890 / 15204]\n",
      "Batch [4900 / 15204]\n",
      "Batch [4910 / 15204]\n",
      "Batch [4920 / 15204]\n",
      "Batch [4930 / 15204]\n",
      "Batch [4940 / 15204]\n",
      "Batch [4950 / 15204]\n",
      "Batch [4960 / 15204]\n",
      "Batch [4970 / 15204]\n",
      "Batch [4980 / 15204]\n",
      "Batch [4990 / 15204]\n",
      "Batch [5000 / 15204]\n",
      "Batch [5010 / 15204]\n",
      "Batch [5020 / 15204]\n",
      "Batch [5030 / 15204]\n",
      "Batch [5040 / 15204]\n",
      "Batch [5050 / 15204]\n",
      "Batch [5060 / 15204]\n",
      "Batch [5070 / 15204]\n",
      "Batch [5080 / 15204]\n",
      "Batch [5090 / 15204]\n",
      "Batch [5100 / 15204]\n",
      "Batch [5110 / 15204]\n",
      "Batch [5120 / 15204]\n",
      "Batch [5130 / 15204]\n",
      "Batch [5140 / 15204]\n",
      "Batch [5150 / 15204]\n",
      "Batch [5160 / 15204]\n",
      "Batch [5170 / 15204]\n",
      "Batch [5180 / 15204]\n",
      "Batch [5190 / 15204]\n",
      "Batch [5200 / 15204]\n",
      "Batch [5210 / 15204]\n",
      "Batch [5220 / 15204]\n",
      "Batch [5230 / 15204]\n",
      "Batch [5240 / 15204]\n",
      "Batch [5250 / 15204]\n",
      "Batch [5260 / 15204]\n",
      "Batch [5270 / 15204]\n",
      "Batch [5280 / 15204]\n",
      "Batch [5290 / 15204]\n",
      "Batch [5300 / 15204]\n",
      "Batch [5310 / 15204]\n",
      "Batch [5320 / 15204]\n",
      "Batch [5330 / 15204]\n",
      "Batch [5340 / 15204]\n",
      "Batch [5350 / 15204]\n",
      "Batch [5360 / 15204]\n",
      "Batch [5370 / 15204]\n",
      "Batch [5380 / 15204]\n",
      "Batch [5390 / 15204]\n",
      "Batch [5400 / 15204]\n",
      "Batch [5410 / 15204]\n",
      "Batch [5420 / 15204]\n",
      "Batch [5430 / 15204]\n",
      "Batch [5440 / 15204]\n",
      "Batch [5450 / 15204]\n",
      "Batch [5460 / 15204]\n",
      "Batch [5470 / 15204]\n",
      "Batch [5480 / 15204]\n",
      "Batch [5490 / 15204]\n",
      "Batch [5500 / 15204]\n",
      "Batch [5510 / 15204]\n",
      "Batch [5520 / 15204]\n",
      "Batch [5530 / 15204]\n",
      "Batch [5540 / 15204]\n",
      "Batch [5550 / 15204]\n",
      "Batch [5560 / 15204]\n",
      "Batch [5570 / 15204]\n",
      "Batch [5580 / 15204]\n",
      "Batch [5590 / 15204]\n",
      "Batch [5600 / 15204]\n",
      "Batch [5610 / 15204]\n",
      "Batch [5620 / 15204]\n",
      "Batch [5630 / 15204]\n",
      "Batch [5640 / 15204]\n",
      "Batch [5650 / 15204]\n",
      "Batch [5660 / 15204]\n",
      "Batch [5670 / 15204]\n",
      "Batch [5680 / 15204]\n",
      "Batch [5690 / 15204]\n",
      "Batch [5700 / 15204]\n",
      "Batch [5710 / 15204]\n",
      "Batch [5720 / 15204]\n",
      "Batch [5730 / 15204]\n",
      "Batch [5740 / 15204]\n",
      "Batch [5750 / 15204]\n",
      "Batch [5760 / 15204]\n",
      "Batch [5770 / 15204]\n",
      "Batch [5780 / 15204]\n",
      "Batch [5790 / 15204]\n",
      "Batch [5800 / 15204]\n",
      "Batch [5810 / 15204]\n",
      "Batch [5820 / 15204]\n",
      "Batch [5830 / 15204]\n",
      "Batch [5840 / 15204]\n",
      "Batch [5850 / 15204]\n",
      "Batch [5860 / 15204]\n",
      "Batch [5870 / 15204]\n",
      "Batch [5880 / 15204]\n",
      "Batch [5890 / 15204]\n",
      "Batch [5900 / 15204]\n",
      "Batch [5910 / 15204]\n",
      "Batch [5920 / 15204]\n",
      "Batch [5930 / 15204]\n",
      "Batch [5940 / 15204]\n",
      "Batch [5950 / 15204]\n",
      "Batch [5960 / 15204]\n",
      "Batch [5970 / 15204]\n",
      "Batch [5980 / 15204]\n",
      "Batch [5990 / 15204]\n",
      "Batch [6000 / 15204]\n",
      "Batch [6010 / 15204]\n",
      "Batch [6020 / 15204]\n",
      "Batch [6030 / 15204]\n",
      "Batch [6040 / 15204]\n",
      "Batch [6050 / 15204]\n",
      "Batch [6060 / 15204]\n",
      "Batch [6070 / 15204]\n",
      "Batch [6080 / 15204]\n",
      "Batch [6090 / 15204]\n",
      "Batch [6100 / 15204]\n",
      "Batch [6110 / 15204]\n",
      "Batch [6120 / 15204]\n",
      "Batch [6130 / 15204]\n",
      "Batch [6140 / 15204]\n",
      "Batch [6150 / 15204]\n",
      "Batch [6160 / 15204]\n",
      "Batch [6170 / 15204]\n",
      "Batch [6180 / 15204]\n",
      "Batch [6190 / 15204]\n",
      "Batch [6200 / 15204]\n",
      "Batch [6210 / 15204]\n",
      "Batch [6220 / 15204]\n",
      "Batch [6230 / 15204]\n",
      "Batch [6240 / 15204]\n",
      "Batch [6250 / 15204]\n",
      "Batch [6260 / 15204]\n",
      "Batch [6270 / 15204]\n",
      "Batch [6280 / 15204]\n",
      "Batch [6290 / 15204]\n",
      "Batch [6300 / 15204]\n",
      "Batch [6310 / 15204]\n",
      "Batch [6320 / 15204]\n",
      "Batch [6330 / 15204]\n",
      "Batch [6340 / 15204]\n",
      "Batch [6350 / 15204]\n",
      "Batch [6360 / 15204]\n",
      "Batch [6370 / 15204]\n",
      "Batch [6380 / 15204]\n",
      "Batch [6390 / 15204]\n",
      "Batch [6400 / 15204]\n",
      "Batch [6410 / 15204]\n",
      "Batch [6420 / 15204]\n",
      "Batch [6430 / 15204]\n",
      "Batch [6440 / 15204]\n",
      "Batch [6450 / 15204]\n",
      "Batch [6460 / 15204]\n",
      "Batch [6470 / 15204]\n",
      "Batch [6480 / 15204]\n",
      "Batch [6490 / 15204]\n",
      "Batch [6500 / 15204]\n",
      "Batch [6510 / 15204]\n",
      "Batch [6520 / 15204]\n",
      "Batch [6530 / 15204]\n",
      "Batch [6540 / 15204]\n",
      "Batch [6550 / 15204]\n",
      "Batch [6560 / 15204]\n",
      "Batch [6570 / 15204]\n",
      "Batch [6580 / 15204]\n",
      "Batch [6590 / 15204]\n",
      "Batch [6600 / 15204]\n",
      "Batch [6610 / 15204]\n",
      "Batch [6620 / 15204]\n",
      "Batch [6630 / 15204]\n",
      "Batch [6640 / 15204]\n",
      "Batch [6650 / 15204]\n",
      "Batch [6660 / 15204]\n",
      "Batch [6670 / 15204]\n",
      "Batch [6680 / 15204]\n",
      "Batch [6690 / 15204]\n",
      "Batch [6700 / 15204]\n",
      "Batch [6710 / 15204]\n",
      "Batch [6720 / 15204]\n",
      "Batch [6730 / 15204]\n",
      "Batch [6740 / 15204]\n",
      "Batch [6750 / 15204]\n",
      "Batch [6760 / 15204]\n",
      "Batch [6770 / 15204]\n",
      "Batch [6780 / 15204]\n",
      "Batch [6790 / 15204]\n",
      "Batch [6800 / 15204]\n",
      "Batch [6810 / 15204]\n",
      "Batch [6820 / 15204]\n",
      "Batch [6830 / 15204]\n",
      "Batch [6840 / 15204]\n",
      "Batch [6850 / 15204]\n",
      "Batch [6860 / 15204]\n",
      "Batch [6870 / 15204]\n",
      "Batch [6880 / 15204]\n",
      "Batch [6890 / 15204]\n",
      "Batch [6900 / 15204]\n",
      "Batch [6910 / 15204]\n",
      "Batch [6920 / 15204]\n",
      "Batch [6930 / 15204]\n",
      "Batch [6940 / 15204]\n",
      "Batch [6950 / 15204]\n",
      "Batch [6960 / 15204]\n",
      "Batch [6970 / 15204]\n",
      "Batch [6980 / 15204]\n",
      "Batch [6990 / 15204]\n",
      "Batch [7000 / 15204]\n",
      "Batch [7010 / 15204]\n",
      "Batch [7020 / 15204]\n",
      "Batch [7030 / 15204]\n",
      "Batch [7040 / 15204]\n",
      "Batch [7050 / 15204]\n",
      "Batch [7060 / 15204]\n",
      "Batch [7070 / 15204]\n",
      "Batch [7080 / 15204]\n",
      "Batch [7090 / 15204]\n",
      "Batch [7100 / 15204]\n",
      "Batch [7110 / 15204]\n",
      "Batch [7120 / 15204]\n",
      "Batch [7130 / 15204]\n",
      "Batch [7140 / 15204]\n",
      "Batch [7150 / 15204]\n",
      "Batch [7160 / 15204]\n",
      "Batch [7170 / 15204]\n",
      "Batch [7180 / 15204]\n",
      "Batch [7190 / 15204]\n",
      "Batch [7200 / 15204]\n",
      "Batch [7210 / 15204]\n",
      "Batch [7220 / 15204]\n",
      "Batch [7230 / 15204]\n",
      "Batch [7240 / 15204]\n",
      "Batch [7250 / 15204]\n",
      "Batch [7260 / 15204]\n",
      "Batch [7270 / 15204]\n",
      "Batch [7280 / 15204]\n",
      "Batch [7290 / 15204]\n",
      "Batch [7300 / 15204]\n",
      "Batch [7310 / 15204]\n",
      "Batch [7320 / 15204]\n",
      "Batch [7330 / 15204]\n",
      "Batch [7340 / 15204]\n",
      "Batch [7350 / 15204]\n",
      "Batch [7360 / 15204]\n",
      "Batch [7370 / 15204]\n",
      "Batch [7380 / 15204]\n",
      "Batch [7390 / 15204]\n",
      "Batch [7400 / 15204]\n",
      "Batch [7410 / 15204]\n",
      "Batch [7420 / 15204]\n",
      "Batch [7430 / 15204]\n",
      "Batch [7440 / 15204]\n",
      "Batch [7450 / 15204]\n",
      "Batch [7460 / 15204]\n",
      "Batch [7470 / 15204]\n",
      "Batch [7480 / 15204]\n",
      "Batch [7490 / 15204]\n",
      "Batch [7500 / 15204]\n",
      "Batch [7510 / 15204]\n",
      "Batch [7520 / 15204]\n",
      "Batch [7530 / 15204]\n",
      "Batch [7540 / 15204]\n",
      "Batch [7550 / 15204]\n",
      "Batch [7560 / 15204]\n",
      "Batch [7570 / 15204]\n",
      "Batch [7580 / 15204]\n",
      "Batch [7590 / 15204]\n",
      "Batch [7600 / 15204]\n",
      "Batch [7610 / 15204]\n",
      "Batch [7620 / 15204]\n",
      "Batch [7630 / 15204]\n",
      "Batch [7640 / 15204]\n",
      "Batch [7650 / 15204]\n",
      "Batch [7660 / 15204]\n",
      "Batch [7670 / 15204]\n",
      "Batch [7680 / 15204]\n",
      "Batch [7690 / 15204]\n",
      "Batch [7700 / 15204]\n",
      "Batch [7710 / 15204]\n",
      "Batch [7720 / 15204]\n",
      "Batch [7730 / 15204]\n",
      "Batch [7740 / 15204]\n",
      "Batch [7750 / 15204]\n",
      "Batch [7760 / 15204]\n",
      "Batch [7770 / 15204]\n",
      "Batch [7780 / 15204]\n",
      "Batch [7790 / 15204]\n",
      "Batch [7800 / 15204]\n",
      "Batch [7810 / 15204]\n",
      "Batch [7820 / 15204]\n",
      "Batch [7830 / 15204]\n",
      "Batch [7840 / 15204]\n",
      "Batch [7850 / 15204]\n",
      "Batch [7860 / 15204]\n",
      "Batch [7870 / 15204]\n",
      "Batch [7880 / 15204]\n",
      "Batch [7890 / 15204]\n",
      "Batch [7900 / 15204]\n",
      "Batch [7910 / 15204]\n",
      "Batch [7920 / 15204]\n",
      "Batch [7930 / 15204]\n",
      "Batch [7940 / 15204]\n",
      "Batch [7950 / 15204]\n",
      "Batch [7960 / 15204]\n",
      "Batch [7970 / 15204]\n",
      "Batch [7980 / 15204]\n",
      "Batch [7990 / 15204]\n",
      "Batch [8000 / 15204]\n",
      "Batch [8010 / 15204]\n",
      "Batch [8020 / 15204]\n",
      "Batch [8030 / 15204]\n",
      "Batch [8040 / 15204]\n",
      "Batch [8050 / 15204]\n",
      "Batch [8060 / 15204]\n",
      "Batch [8070 / 15204]\n",
      "Batch [8080 / 15204]\n",
      "Batch [8090 / 15204]\n",
      "Batch [8100 / 15204]\n",
      "Batch [8110 / 15204]\n",
      "Batch [8120 / 15204]\n",
      "Batch [8130 / 15204]\n",
      "Batch [8140 / 15204]\n",
      "Batch [8150 / 15204]\n",
      "Batch [8160 / 15204]\n",
      "Batch [8170 / 15204]\n",
      "Batch [8180 / 15204]\n",
      "Batch [8190 / 15204]\n",
      "Batch [8200 / 15204]\n",
      "Batch [8210 / 15204]\n",
      "Batch [8220 / 15204]\n",
      "Batch [8230 / 15204]\n",
      "Batch [8240 / 15204]\n",
      "Batch [8250 / 15204]\n",
      "Batch [8260 / 15204]\n",
      "Batch [8270 / 15204]\n",
      "Batch [8280 / 15204]\n",
      "Batch [8290 / 15204]\n",
      "Batch [8300 / 15204]\n",
      "Batch [8310 / 15204]\n",
      "Batch [8320 / 15204]\n",
      "Batch [8330 / 15204]\n",
      "Batch [8340 / 15204]\n",
      "Batch [8350 / 15204]\n",
      "Batch [8360 / 15204]\n",
      "Batch [8370 / 15204]\n",
      "Batch [8380 / 15204]\n",
      "Batch [8390 / 15204]\n",
      "Batch [8400 / 15204]\n",
      "Batch [8410 / 15204]\n",
      "Batch [8420 / 15204]\n",
      "Batch [8430 / 15204]\n",
      "Batch [8440 / 15204]\n",
      "Batch [8450 / 15204]\n",
      "Batch [8460 / 15204]\n",
      "Batch [8470 / 15204]\n",
      "Batch [8480 / 15204]\n",
      "Batch [8490 / 15204]\n",
      "Batch [8500 / 15204]\n",
      "Batch [8510 / 15204]\n",
      "Batch [8520 / 15204]\n",
      "Batch [8530 / 15204]\n",
      "Batch [8540 / 15204]\n",
      "Batch [8550 / 15204]\n",
      "Batch [8560 / 15204]\n",
      "Batch [8570 / 15204]\n",
      "Batch [8580 / 15204]\n",
      "Batch [8590 / 15204]\n",
      "Batch [8600 / 15204]\n",
      "Batch [8610 / 15204]\n",
      "Batch [8620 / 15204]\n",
      "Batch [8630 / 15204]\n",
      "Batch [8640 / 15204]\n",
      "Batch [8650 / 15204]\n",
      "Batch [8660 / 15204]\n",
      "Batch [8670 / 15204]\n",
      "Batch [8680 / 15204]\n",
      "Batch [8690 / 15204]\n",
      "Batch [8700 / 15204]\n",
      "Batch [8710 / 15204]\n",
      "Batch [8720 / 15204]\n",
      "Batch [8730 / 15204]\n",
      "Batch [8740 / 15204]\n",
      "Batch [8750 / 15204]\n",
      "Batch [8760 / 15204]\n",
      "Batch [8770 / 15204]\n",
      "Batch [8780 / 15204]\n",
      "Batch [8790 / 15204]\n",
      "Batch [8800 / 15204]\n",
      "Batch [8810 / 15204]\n",
      "Batch [8820 / 15204]\n",
      "Batch [8830 / 15204]\n",
      "Batch [8840 / 15204]\n",
      "Batch [8850 / 15204]\n",
      "Batch [8860 / 15204]\n",
      "Batch [8870 / 15204]\n",
      "Batch [8880 / 15204]\n",
      "Batch [8890 / 15204]\n",
      "Batch [8900 / 15204]\n",
      "Batch [8910 / 15204]\n",
      "Batch [8920 / 15204]\n",
      "Batch [8930 / 15204]\n",
      "Batch [8940 / 15204]\n",
      "Batch [8950 / 15204]\n",
      "Batch [8960 / 15204]\n",
      "Batch [8970 / 15204]\n",
      "Batch [8980 / 15204]\n",
      "Batch [8990 / 15204]\n",
      "Batch [9000 / 15204]\n",
      "Batch [9010 / 15204]\n",
      "Batch [9020 / 15204]\n",
      "Batch [9030 / 15204]\n",
      "Batch [9040 / 15204]\n",
      "Batch [9050 / 15204]\n",
      "Batch [9060 / 15204]\n",
      "Batch [9070 / 15204]\n",
      "Batch [9080 / 15204]\n",
      "Batch [9090 / 15204]\n",
      "Batch [9100 / 15204]\n",
      "Batch [9110 / 15204]\n",
      "Batch [9120 / 15204]\n",
      "Batch [9130 / 15204]\n",
      "Batch [9140 / 15204]\n",
      "Batch [9150 / 15204]\n",
      "Batch [9160 / 15204]\n",
      "Batch [9170 / 15204]\n",
      "Batch [9180 / 15204]\n",
      "Batch [9190 / 15204]\n",
      "Batch [9200 / 15204]\n",
      "Batch [9210 / 15204]\n",
      "Batch [9220 / 15204]\n",
      "Batch [9230 / 15204]\n",
      "Batch [9240 / 15204]\n",
      "Batch [9250 / 15204]\n",
      "Batch [9260 / 15204]\n",
      "Batch [9270 / 15204]\n",
      "Batch [9280 / 15204]\n",
      "Batch [9290 / 15204]\n",
      "Batch [9300 / 15204]\n",
      "Batch [9310 / 15204]\n",
      "Batch [9320 / 15204]\n",
      "Batch [9330 / 15204]\n",
      "Batch [9340 / 15204]\n",
      "Batch [9350 / 15204]\n",
      "Batch [9360 / 15204]\n",
      "Batch [9370 / 15204]\n",
      "Batch [9380 / 15204]\n",
      "Batch [9390 / 15204]\n",
      "Batch [9400 / 15204]\n",
      "Batch [9410 / 15204]\n",
      "Batch [9420 / 15204]\n",
      "Batch [9430 / 15204]\n",
      "Batch [9440 / 15204]\n",
      "Batch [9450 / 15204]\n",
      "Batch [9460 / 15204]\n",
      "Batch [9470 / 15204]\n",
      "Batch [9480 / 15204]\n",
      "Batch [9490 / 15204]\n",
      "Batch [9500 / 15204]\n",
      "Batch [9510 / 15204]\n",
      "Batch [9520 / 15204]\n",
      "Batch [9530 / 15204]\n",
      "Batch [9540 / 15204]\n",
      "Batch [9550 / 15204]\n",
      "Batch [9560 / 15204]\n",
      "Batch [9570 / 15204]\n",
      "Batch [9580 / 15204]\n",
      "Batch [9590 / 15204]\n",
      "Batch [9600 / 15204]\n",
      "Batch [9610 / 15204]\n",
      "Batch [9620 / 15204]\n",
      "Batch [9630 / 15204]\n",
      "Batch [9640 / 15204]\n",
      "Batch [9650 / 15204]\n",
      "Batch [9660 / 15204]\n",
      "Batch [9670 / 15204]\n",
      "Batch [9680 / 15204]\n",
      "Batch [9690 / 15204]\n",
      "Batch [9700 / 15204]\n",
      "Batch [9710 / 15204]\n",
      "Batch [9720 / 15204]\n",
      "Batch [9730 / 15204]\n",
      "Batch [9740 / 15204]\n",
      "Batch [9750 / 15204]\n",
      "Batch [9760 / 15204]\n",
      "Batch [9770 / 15204]\n",
      "Batch [9780 / 15204]\n",
      "Batch [9790 / 15204]\n",
      "Batch [9800 / 15204]\n",
      "Batch [9810 / 15204]\n",
      "Batch [9820 / 15204]\n",
      "Batch [9830 / 15204]\n",
      "Batch [9840 / 15204]\n",
      "Batch [9850 / 15204]\n",
      "Batch [9860 / 15204]\n",
      "Batch [9870 / 15204]\n",
      "Batch [9880 / 15204]\n",
      "Batch [9890 / 15204]\n",
      "Batch [9900 / 15204]\n",
      "Batch [9910 / 15204]\n",
      "Batch [9920 / 15204]\n",
      "Batch [9930 / 15204]\n",
      "Batch [9940 / 15204]\n",
      "Batch [9950 / 15204]\n",
      "Batch [9960 / 15204]\n",
      "Batch [9970 / 15204]\n",
      "Batch [9980 / 15204]\n",
      "Batch [9990 / 15204]\n",
      "Batch [10000 / 15204]\n",
      "Batch [10010 / 15204]\n",
      "Batch [10020 / 15204]\n",
      "Batch [10030 / 15204]\n",
      "Batch [10040 / 15204]\n",
      "Batch [10050 / 15204]\n",
      "Batch [10060 / 15204]\n",
      "Batch [10070 / 15204]\n",
      "Batch [10080 / 15204]\n",
      "Batch [10090 / 15204]\n",
      "Batch [10100 / 15204]\n",
      "Batch [10110 / 15204]\n",
      "Batch [10120 / 15204]\n",
      "Batch [10130 / 15204]\n",
      "Batch [10140 / 15204]\n",
      "Batch [10150 / 15204]\n",
      "Batch [10160 / 15204]\n",
      "Batch [10170 / 15204]\n",
      "Batch [10180 / 15204]\n",
      "Batch [10190 / 15204]\n",
      "Batch [10200 / 15204]\n",
      "Batch [10210 / 15204]\n",
      "Batch [10220 / 15204]\n",
      "Batch [10230 / 15204]\n",
      "Batch [10240 / 15204]\n",
      "Batch [10250 / 15204]\n",
      "Batch [10260 / 15204]\n",
      "Batch [10270 / 15204]\n",
      "Batch [10280 / 15204]\n",
      "Batch [10290 / 15204]\n",
      "Batch [10300 / 15204]\n",
      "Batch [10310 / 15204]\n",
      "Batch [10320 / 15204]\n",
      "Batch [10330 / 15204]\n",
      "Batch [10340 / 15204]\n",
      "Batch [10350 / 15204]\n",
      "Batch [10360 / 15204]\n",
      "Batch [10370 / 15204]\n",
      "Batch [10380 / 15204]\n",
      "Batch [10390 / 15204]\n",
      "Batch [10400 / 15204]\n",
      "Batch [10410 / 15204]\n",
      "Batch [10420 / 15204]\n",
      "Batch [10430 / 15204]\n",
      "Batch [10440 / 15204]\n",
      "Batch [10450 / 15204]\n",
      "Batch [10460 / 15204]\n",
      "Batch [10470 / 15204]\n",
      "Batch [10480 / 15204]\n",
      "Batch [10490 / 15204]\n",
      "Batch [10500 / 15204]\n",
      "Batch [10510 / 15204]\n",
      "Batch [10520 / 15204]\n",
      "Batch [10530 / 15204]\n",
      "Batch [10540 / 15204]\n",
      "Batch [10550 / 15204]\n",
      "Batch [10560 / 15204]\n",
      "Batch [10570 / 15204]\n",
      "Batch [10580 / 15204]\n",
      "Batch [10590 / 15204]\n",
      "Batch [10600 / 15204]\n",
      "Batch [10610 / 15204]\n",
      "Batch [10620 / 15204]\n",
      "Batch [10630 / 15204]\n",
      "Batch [10640 / 15204]\n",
      "Batch [10650 / 15204]\n",
      "Batch [10660 / 15204]\n",
      "Batch [10670 / 15204]\n",
      "Batch [10680 / 15204]\n",
      "Batch [10690 / 15204]\n",
      "Batch [10700 / 15204]\n",
      "Batch [10710 / 15204]\n",
      "Batch [10720 / 15204]\n",
      "Batch [10730 / 15204]\n",
      "Batch [10740 / 15204]\n",
      "Batch [10750 / 15204]\n",
      "Batch [10760 / 15204]\n",
      "Batch [10770 / 15204]\n",
      "Batch [10780 / 15204]\n",
      "Batch [10790 / 15204]\n",
      "Batch [10800 / 15204]\n",
      "Batch [10810 / 15204]\n",
      "Batch [10820 / 15204]\n",
      "Batch [10830 / 15204]\n",
      "Batch [10840 / 15204]\n",
      "Batch [10850 / 15204]\n",
      "Batch [10860 / 15204]\n",
      "Batch [10870 / 15204]\n",
      "Batch [10880 / 15204]\n",
      "Batch [10890 / 15204]\n",
      "Batch [10900 / 15204]\n",
      "Batch [10910 / 15204]\n",
      "Batch [10920 / 15204]\n",
      "Batch [10930 / 15204]\n",
      "Batch [10940 / 15204]\n",
      "Batch [10950 / 15204]\n",
      "Batch [10960 / 15204]\n",
      "Batch [10970 / 15204]\n",
      "Batch [10980 / 15204]\n",
      "Batch [10990 / 15204]\n",
      "Batch [11000 / 15204]\n",
      "Batch [11010 / 15204]\n",
      "Batch [11020 / 15204]\n",
      "Batch [11030 / 15204]\n",
      "Batch [11040 / 15204]\n",
      "Batch [11050 / 15204]\n",
      "Batch [11060 / 15204]\n",
      "Batch [11070 / 15204]\n",
      "Batch [11080 / 15204]\n",
      "Batch [11090 / 15204]\n",
      "Batch [11100 / 15204]\n",
      "Batch [11110 / 15204]\n",
      "Batch [11120 / 15204]\n",
      "Batch [11130 / 15204]\n",
      "Batch [11140 / 15204]\n",
      "Batch [11150 / 15204]\n",
      "Batch [11160 / 15204]\n",
      "Batch [11170 / 15204]\n",
      "Batch [11180 / 15204]\n",
      "Batch [11190 / 15204]\n",
      "Batch [11200 / 15204]\n",
      "Batch [11210 / 15204]\n",
      "Batch [11220 / 15204]\n",
      "Batch [11230 / 15204]\n",
      "Batch [11240 / 15204]\n",
      "Batch [11250 / 15204]\n",
      "Batch [11260 / 15204]\n",
      "Batch [11270 / 15204]\n",
      "Batch [11280 / 15204]\n",
      "Batch [11290 / 15204]\n",
      "Batch [11300 / 15204]\n",
      "Batch [11310 / 15204]\n",
      "Batch [11320 / 15204]\n",
      "Batch [11330 / 15204]\n",
      "Batch [11340 / 15204]\n",
      "Batch [11350 / 15204]\n",
      "Batch [11360 / 15204]\n",
      "Batch [11370 / 15204]\n",
      "Batch [11380 / 15204]\n",
      "Batch [11390 / 15204]\n",
      "Batch [11400 / 15204]\n",
      "Batch [11410 / 15204]\n",
      "Batch [11420 / 15204]\n",
      "Batch [11430 / 15204]\n",
      "Batch [11440 / 15204]\n",
      "Batch [11450 / 15204]\n",
      "Batch [11460 / 15204]\n",
      "Batch [11470 / 15204]\n",
      "Batch [11480 / 15204]\n",
      "Batch [11490 / 15204]\n",
      "Batch [11500 / 15204]\n",
      "Batch [11510 / 15204]\n",
      "Batch [11520 / 15204]\n",
      "Batch [11530 / 15204]\n",
      "Batch [11540 / 15204]\n",
      "Batch [11550 / 15204]\n",
      "Batch [11560 / 15204]\n",
      "Batch [11570 / 15204]\n",
      "Batch [11580 / 15204]\n",
      "Batch [11590 / 15204]\n",
      "Batch [11600 / 15204]\n",
      "Batch [11610 / 15204]\n",
      "Batch [11620 / 15204]\n",
      "Batch [11630 / 15204]\n",
      "Batch [11640 / 15204]\n",
      "Batch [11650 / 15204]\n",
      "Batch [11660 / 15204]\n",
      "Batch [11670 / 15204]\n",
      "Batch [11680 / 15204]\n",
      "Batch [11690 / 15204]\n",
      "Batch [11700 / 15204]\n",
      "Batch [11710 / 15204]\n",
      "Batch [11720 / 15204]\n",
      "Batch [11730 / 15204]\n",
      "Batch [11740 / 15204]\n",
      "Batch [11750 / 15204]\n",
      "Batch [11760 / 15204]\n",
      "Batch [11770 / 15204]\n",
      "Batch [11780 / 15204]\n",
      "Batch [11790 / 15204]\n",
      "Batch [11800 / 15204]\n",
      "Batch [11810 / 15204]\n",
      "Batch [11820 / 15204]\n",
      "Batch [11830 / 15204]\n",
      "Batch [11840 / 15204]\n",
      "Batch [11850 / 15204]\n",
      "Batch [11860 / 15204]\n",
      "Batch [11870 / 15204]\n",
      "Batch [11880 / 15204]\n",
      "Batch [11890 / 15204]\n",
      "Batch [11900 / 15204]\n",
      "Batch [11910 / 15204]\n",
      "Batch [11920 / 15204]\n",
      "Batch [11930 / 15204]\n",
      "Batch [11940 / 15204]\n",
      "Batch [11950 / 15204]\n",
      "Batch [11960 / 15204]\n",
      "Batch [11970 / 15204]\n",
      "Batch [11980 / 15204]\n",
      "Batch [11990 / 15204]\n",
      "Batch [12000 / 15204]\n",
      "Batch [12010 / 15204]\n",
      "Batch [12020 / 15204]\n",
      "Batch [12030 / 15204]\n",
      "Batch [12040 / 15204]\n",
      "Batch [12050 / 15204]\n",
      "Batch [12060 / 15204]\n",
      "Batch [12070 / 15204]\n",
      "Batch [12080 / 15204]\n",
      "Batch [12090 / 15204]\n",
      "Batch [12100 / 15204]\n",
      "Batch [12110 / 15204]\n",
      "Batch [12120 / 15204]\n",
      "Batch [12130 / 15204]\n",
      "Batch [12140 / 15204]\n",
      "Batch [12150 / 15204]\n",
      "Batch [12160 / 15204]\n",
      "Batch [12170 / 15204]\n",
      "Batch [12180 / 15204]\n",
      "Batch [12190 / 15204]\n",
      "Batch [12200 / 15204]\n",
      "Batch [12210 / 15204]\n",
      "Batch [12220 / 15204]\n",
      "Batch [12230 / 15204]\n",
      "Batch [12240 / 15204]\n",
      "Batch [12250 / 15204]\n",
      "Batch [12260 / 15204]\n",
      "Batch [12270 / 15204]\n",
      "Batch [12280 / 15204]\n",
      "Batch [12290 / 15204]\n",
      "Batch [12300 / 15204]\n",
      "Batch [12310 / 15204]\n",
      "Batch [12320 / 15204]\n",
      "Batch [12330 / 15204]\n",
      "Batch [12340 / 15204]\n",
      "Batch [12350 / 15204]\n",
      "Batch [12360 / 15204]\n",
      "Batch [12370 / 15204]\n",
      "Batch [12380 / 15204]\n",
      "Batch [12390 / 15204]\n",
      "Batch [12400 / 15204]\n",
      "Batch [12410 / 15204]\n",
      "Batch [12420 / 15204]\n",
      "Batch [12430 / 15204]\n",
      "Batch [12440 / 15204]\n",
      "Batch [12450 / 15204]\n",
      "Batch [12460 / 15204]\n",
      "Batch [12470 / 15204]\n",
      "Batch [12480 / 15204]\n",
      "Batch [12490 / 15204]\n",
      "Batch [12500 / 15204]\n",
      "Batch [12510 / 15204]\n",
      "Batch [12520 / 15204]\n",
      "Batch [12530 / 15204]\n",
      "Batch [12540 / 15204]\n",
      "Batch [12550 / 15204]\n",
      "Batch [12560 / 15204]\n",
      "Batch [12570 / 15204]\n",
      "Batch [12580 / 15204]\n",
      "Batch [12590 / 15204]\n",
      "Batch [12600 / 15204]\n",
      "Batch [12610 / 15204]\n",
      "Batch [12620 / 15204]\n",
      "Batch [12630 / 15204]\n",
      "Batch [12640 / 15204]\n",
      "Batch [12650 / 15204]\n",
      "Batch [12660 / 15204]\n",
      "Batch [12670 / 15204]\n",
      "Batch [12680 / 15204]\n",
      "Batch [12690 / 15204]\n",
      "Batch [12700 / 15204]\n",
      "Batch [12710 / 15204]\n",
      "Batch [12720 / 15204]\n",
      "Batch [12730 / 15204]\n",
      "Batch [12740 / 15204]\n",
      "Batch [12750 / 15204]\n",
      "Batch [12760 / 15204]\n",
      "Batch [12770 / 15204]\n",
      "Batch [12780 / 15204]\n",
      "Batch [12790 / 15204]\n",
      "Batch [12800 / 15204]\n",
      "Batch [12810 / 15204]\n",
      "Batch [12820 / 15204]\n",
      "Batch [12830 / 15204]\n",
      "Batch [12840 / 15204]\n",
      "Batch [12850 / 15204]\n",
      "Batch [12860 / 15204]\n",
      "Batch [12870 / 15204]\n",
      "Batch [12880 / 15204]\n",
      "Batch [12890 / 15204]\n",
      "Batch [12900 / 15204]\n",
      "Batch [12910 / 15204]\n",
      "Batch [12920 / 15204]\n",
      "Batch [12930 / 15204]\n",
      "Batch [12940 / 15204]\n",
      "Batch [12950 / 15204]\n",
      "Batch [12960 / 15204]\n",
      "Batch [12970 / 15204]\n",
      "Batch [12980 / 15204]\n",
      "Batch [12990 / 15204]\n",
      "Batch [13000 / 15204]\n",
      "Batch [13010 / 15204]\n",
      "Batch [13020 / 15204]\n",
      "Batch [13030 / 15204]\n",
      "Batch [13040 / 15204]\n",
      "Batch [13050 / 15204]\n",
      "Batch [13060 / 15204]\n",
      "Batch [13070 / 15204]\n",
      "Batch [13080 / 15204]\n",
      "Batch [13090 / 15204]\n",
      "Batch [13100 / 15204]\n",
      "Batch [13110 / 15204]\n",
      "Batch [13120 / 15204]\n",
      "Batch [13130 / 15204]\n",
      "Batch [13140 / 15204]\n",
      "Batch [13150 / 15204]\n",
      "Batch [13160 / 15204]\n",
      "Batch [13170 / 15204]\n",
      "Batch [13180 / 15204]\n",
      "Batch [13190 / 15204]\n",
      "Batch [13200 / 15204]\n",
      "Batch [13210 / 15204]\n",
      "Batch [13220 / 15204]\n",
      "Batch [13230 / 15204]\n",
      "Batch [13240 / 15204]\n",
      "Batch [13250 / 15204]\n",
      "Batch [13260 / 15204]\n",
      "Batch [13270 / 15204]\n",
      "Batch [13280 / 15204]\n",
      "Batch [13290 / 15204]\n",
      "Batch [13300 / 15204]\n",
      "Batch [13310 / 15204]\n",
      "Batch [13320 / 15204]\n",
      "Batch [13330 / 15204]\n",
      "Batch [13340 / 15204]\n",
      "Batch [13350 / 15204]\n",
      "Batch [13360 / 15204]\n",
      "Batch [13370 / 15204]\n",
      "Batch [13380 / 15204]\n",
      "Batch [13390 / 15204]\n",
      "Batch [13400 / 15204]\n",
      "Batch [13410 / 15204]\n",
      "Batch [13420 / 15204]\n",
      "Batch [13430 / 15204]\n",
      "Batch [13440 / 15204]\n",
      "Batch [13450 / 15204]\n",
      "Batch [13460 / 15204]\n",
      "Batch [13470 / 15204]\n",
      "Batch [13480 / 15204]\n",
      "Batch [13490 / 15204]\n",
      "Batch [13500 / 15204]\n",
      "Batch [13510 / 15204]\n",
      "Batch [13520 / 15204]\n",
      "Batch [13530 / 15204]\n",
      "Batch [13540 / 15204]\n",
      "Batch [13550 / 15204]\n",
      "Batch [13560 / 15204]\n",
      "Batch [13570 / 15204]\n",
      "Batch [13580 / 15204]\n",
      "Batch [13590 / 15204]\n",
      "Batch [13600 / 15204]\n",
      "Batch [13610 / 15204]\n",
      "Batch [13620 / 15204]\n",
      "Batch [13630 / 15204]\n",
      "Batch [13640 / 15204]\n",
      "Batch [13650 / 15204]\n",
      "Batch [13660 / 15204]\n",
      "Batch [13670 / 15204]\n",
      "Batch [13680 / 15204]\n",
      "Batch [13690 / 15204]\n",
      "Batch [13700 / 15204]\n",
      "Batch [13710 / 15204]\n",
      "Batch [13720 / 15204]\n",
      "Batch [13730 / 15204]\n",
      "Batch [13740 / 15204]\n",
      "Batch [13750 / 15204]\n",
      "Batch [13760 / 15204]\n",
      "Batch [13770 / 15204]\n",
      "Batch [13780 / 15204]\n",
      "Batch [13790 / 15204]\n",
      "Batch [13800 / 15204]\n",
      "Batch [13810 / 15204]\n",
      "Batch [13820 / 15204]\n",
      "Batch [13830 / 15204]\n",
      "Batch [13840 / 15204]\n",
      "Batch [13850 / 15204]\n",
      "Batch [13860 / 15204]\n",
      "Batch [13870 / 15204]\n",
      "Batch [13880 / 15204]\n",
      "Batch [13890 / 15204]\n",
      "Batch [13900 / 15204]\n",
      "Batch [13910 / 15204]\n",
      "Batch [13920 / 15204]\n",
      "Batch [13930 / 15204]\n",
      "Batch [13940 / 15204]\n",
      "Batch [13950 / 15204]\n",
      "Batch [13960 / 15204]\n",
      "Batch [13970 / 15204]\n",
      "Batch [13980 / 15204]\n",
      "Batch [13990 / 15204]\n",
      "Batch [14000 / 15204]\n",
      "Batch [14010 / 15204]\n",
      "Batch [14020 / 15204]\n",
      "Batch [14030 / 15204]\n",
      "Batch [14040 / 15204]\n",
      "Batch [14050 / 15204]\n",
      "Batch [14060 / 15204]\n",
      "Batch [14070 / 15204]\n",
      "Batch [14080 / 15204]\n",
      "Batch [14090 / 15204]\n",
      "Batch [14100 / 15204]\n",
      "Batch [14110 / 15204]\n",
      "Batch [14120 / 15204]\n",
      "Batch [14130 / 15204]\n",
      "Batch [14140 / 15204]\n",
      "Batch [14150 / 15204]\n",
      "Batch [14160 / 15204]\n",
      "Batch [14170 / 15204]\n",
      "Batch [14180 / 15204]\n",
      "Batch [14190 / 15204]\n",
      "Batch [14200 / 15204]\n",
      "Batch [14210 / 15204]\n",
      "Batch [14220 / 15204]\n",
      "Batch [14230 / 15204]\n",
      "Batch [14240 / 15204]\n",
      "Batch [14250 / 15204]\n",
      "Batch [14260 / 15204]\n",
      "Batch [14270 / 15204]\n",
      "Batch [14280 / 15204]\n",
      "Batch [14290 / 15204]\n",
      "Batch [14300 / 15204]\n",
      "Batch [14310 / 15204]\n",
      "Batch [14320 / 15204]\n",
      "Batch [14330 / 15204]\n",
      "Batch [14340 / 15204]\n",
      "Batch [14350 / 15204]\n",
      "Batch [14360 / 15204]\n",
      "Batch [14370 / 15204]\n",
      "Batch [14380 / 15204]\n",
      "Batch [14390 / 15204]\n",
      "Batch [14400 / 15204]\n",
      "Batch [14410 / 15204]\n",
      "Batch [14420 / 15204]\n",
      "Batch [14430 / 15204]\n",
      "Batch [14440 / 15204]\n",
      "Batch [14450 / 15204]\n",
      "Batch [14460 / 15204]\n",
      "Batch [14470 / 15204]\n",
      "Batch [14480 / 15204]\n",
      "Batch [14490 / 15204]\n",
      "Batch [14500 / 15204]\n",
      "Batch [14510 / 15204]\n",
      "Batch [14520 / 15204]\n",
      "Batch [14530 / 15204]\n",
      "Batch [14540 / 15204]\n",
      "Batch [14550 / 15204]\n",
      "Batch [14560 / 15204]\n",
      "Batch [14570 / 15204]\n",
      "Batch [14580 / 15204]\n",
      "Batch [14590 / 15204]\n",
      "Batch [14600 / 15204]\n",
      "Batch [14610 / 15204]\n",
      "Batch [14620 / 15204]\n",
      "Batch [14630 / 15204]\n",
      "Batch [14640 / 15204]\n",
      "Batch [14650 / 15204]\n",
      "Batch [14660 / 15204]\n",
      "Batch [14670 / 15204]\n",
      "Batch [14680 / 15204]\n",
      "Batch [14690 / 15204]\n",
      "Batch [14700 / 15204]\n",
      "Batch [14710 / 15204]\n",
      "Batch [14720 / 15204]\n",
      "Batch [14730 / 15204]\n",
      "Batch [14740 / 15204]\n",
      "Batch [14750 / 15204]\n",
      "Batch [14760 / 15204]\n",
      "Batch [14770 / 15204]\n",
      "Batch [14780 / 15204]\n",
      "Batch [14790 / 15204]\n",
      "Batch [14800 / 15204]\n",
      "Batch [14810 / 15204]\n",
      "Batch [14820 / 15204]\n",
      "Batch [14830 / 15204]\n",
      "Batch [14840 / 15204]\n",
      "Batch [14850 / 15204]\n",
      "Batch [14860 / 15204]\n",
      "Batch [14870 / 15204]\n",
      "Batch [14880 / 15204]\n",
      "Batch [14890 / 15204]\n",
      "Batch [14900 / 15204]\n",
      "Batch [14910 / 15204]\n",
      "Batch [14920 / 15204]\n",
      "Batch [14930 / 15204]\n",
      "Batch [14940 / 15204]\n",
      "Batch [14950 / 15204]\n",
      "Batch [14960 / 15204]\n",
      "Batch [14970 / 15204]\n",
      "Batch [14980 / 15204]\n",
      "Batch [14990 / 15204]\n",
      "Batch [15000 / 15204]\n",
      "Batch [15010 / 15204]\n",
      "Batch [15020 / 15204]\n",
      "Batch [15030 / 15204]\n",
      "Batch [15040 / 15204]\n",
      "Batch [15050 / 15204]\n",
      "Batch [15060 / 15204]\n",
      "Batch [15070 / 15204]\n",
      "Batch [15080 / 15204]\n",
      "Batch [15090 / 15204]\n",
      "Batch [15100 / 15204]\n",
      "Batch [15110 / 15204]\n",
      "Batch [15120 / 15204]\n",
      "Batch [15130 / 15204]\n",
      "Batch [15140 / 15204]\n",
      "Batch [15150 / 15204]\n",
      "Batch [15160 / 15204]\n",
      "Batch [15170 / 15204]\n",
      "Batch [15180 / 15204]\n",
      "Batch [15190 / 15204]\n",
      "Batch [15200 / 15204]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    if device.type == \"cuda\":\n",
    "        for i, data in enumerate(test_loader):\n",
    "            if i % 10 == 9:\n",
    "                print('Batch [%4d / %4d]' % (i+1, len(test_loader)))\n",
    "            inputs = data['pointcloud'].float().to(device)\n",
    "            labels = data['category'].to(device)\n",
    "            outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            all_preds += list(preds.cpu().numpy())  # Move the tensor to CPU and convert to numpy\n",
    "            all_labels += list(labels.cpu().numpy())  # Similarly, move labels to CPU\n",
    "    else:\n",
    "        for i, data in enumerate(test_loader):\n",
    "            if i % 10 == 9:\n",
    "                print('Batch [%4d / %4d]' % (i+1, len(test_loader)))\n",
    "            inputs, labels = data['pointcloud'].float(), data['category']\n",
    "            outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            all_preds += list(preds.numpy())\n",
    "            all_labels += list(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from https://deeplizard.com/learn/video/0LhiS6yu2qQ\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1497011,  418002],\n",
       "       [  22455,    8535]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(all_labels, all_preds);\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: \"Not Hillfort\",\n",
    "    1: \"Hillfort\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plot_confusion_matrix(cm, list(classes.keys()), normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpulocal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
